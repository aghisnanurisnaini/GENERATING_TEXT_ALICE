{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "ig-nyRH_gQwt",
        "outputId": "c3a46f72-0754-463d-ce78-0fde2937a168"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "['\\n', ' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '‘', '’', '“', '”', '\\ufeff']\n",
            "{'\\n': 0, ' ': 1, 'a': 2, 'b': 3, 'c': 4, 'd': 5, 'e': 6, 'f': 7, 'g': 8, 'h': 9, 'i': 10, 'j': 11, 'k': 12, 'l': 13, 'm': 14, 'n': 15, 'o': 16, 'p': 17, 'q': 18, 'r': 19, 's': 20, 't': 21, 'u': 22, 'v': 23, 'w': 24, 'x': 25, 'y': 26, 'z': 27, '‘': 28, '’': 29, '“': 30, '”': 31, '\\ufeff': 32}\n",
            "Total Characters:  139054\n",
            "Total Vocab:  33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m)              │         \u001b[38;5;34m171,650\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │         \u001b[38;5;34m314,368\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m525,312\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3433\u001b[0m)                │         \u001b[38;5;34m882,281\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">171,650</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">314,368</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3433</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">882,281</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,893,611\u001b[0m (7.22 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,893,611</span> (7.22 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,893,611\u001b[0m (7.22 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,893,611</span> (7.22 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM, Embedding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from google.colab import drive\n",
        "import os\n",
        "import string\n",
        "import random\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load and preprocess dataset\n",
        "file_path = '/content/drive/MyDrive/wonderland.txt'\n",
        "\n",
        "# Read and clean the text\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    raw_text = file.read()\n",
        "\n",
        "# Remove punctuation and convert to lowercase\n",
        "raw_text = raw_text.translate(str.maketrans('', '', string.punctuation)).lower()\n",
        "\n",
        "# create mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "print(chars)\n",
        "\n",
        "#here we can see all the unique charecter are mapped to a unique number\n",
        "print(char_to_int)\n",
        "\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print (\"Total Characters: \", n_chars)\n",
        "print (\"Total Vocab: \", n_vocab)\n",
        "\n",
        "# Tokenize the text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([raw_text])\n",
        "sequences = tokenizer.texts_to_sequences([raw_text])[0]\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print (vocab_size)\n",
        "\n",
        "# Prepare input-output pairs for training\n",
        "seq_length = 50\n",
        "X = []\n",
        "y = []\n",
        "for i in range(seq_length, len(sequences)):\n",
        "    X.append(sequences[i - seq_length:i])\n",
        "    y.append(sequences[i])\n",
        "\n",
        "# Pad sequences and one-hot encode the output\n",
        "X = np.array(pad_sequences(X, maxlen=seq_length))\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "\n",
        "# Build the LSTM model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=50, input_length=seq_length),\n",
        "    LSTM(256, return_sequences=True),\n",
        "    Dropout(0.4),\n",
        "    LSTM(256),\n",
        "    Dropout(0.4),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])\n",
        "\n",
        "# Build the model explicitly\n",
        "model.build(input_shape=(None, seq_length))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a checkpoint callback\n",
        "filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}.keras\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "# Train the model\n",
        "epochs = 100  # Increased epochs\n",
        "batch_size = 32  # Experiment with different batch sizes\n",
        "model.fit(X, y, epochs=epochs, batch_size=batch_size, callbacks=callbacks_list)\n",
        "\n",
        "# Menyimpan model yang telah dilatih\n",
        "model.save(\"trained_model.keras\")\n",
        "print(\"Model telah disimpan sebagai 'trained_model.keras'\")\n",
        "\n",
        "# Menampilkan file .keras di direktori kerja\n",
        "files = [f for f in os.listdir() if f.endswith('.keras')]\n",
        "print(\"Files found:\", files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxEXLOLlgxQl",
        "outputId": "99cfa7e9-a298-4577-af32-4c23d77fb02d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m820/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0595 - loss: 6.6446\n",
            "Epoch 1: loss improved from inf to 6.45643, saving model to weights-improvement-01-6.4564.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 12ms/step - accuracy: 0.0595 - loss: 6.6437\n",
            "Epoch 2/100\n",
            "\u001b[1m822/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0612 - loss: 6.1774\n",
            "Epoch 2: loss improved from 6.45643 to 6.15935, saving model to weights-improvement-02-6.1594.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.0612 - loss: 6.1774\n",
            "Epoch 3/100\n",
            "\u001b[1m819/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0674 - loss: 6.0522\n",
            "Epoch 3: loss improved from 6.15935 to 5.99741, saving model to weights-improvement-03-5.9974.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.0674 - loss: 6.0518\n",
            "Epoch 4/100\n",
            "\u001b[1m822/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0766 - loss: 5.8406\n",
            "Epoch 4: loss improved from 5.99741 to 5.84796, saving model to weights-improvement-04-5.8480.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.0766 - loss: 5.8407\n",
            "Epoch 5/100\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0793 - loss: 5.7042\n",
            "Epoch 5: loss improved from 5.84796 to 5.70632, saving model to weights-improvement-05-5.7063.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - accuracy: 0.0793 - loss: 5.7042\n",
            "Epoch 6/100\n",
            "\u001b[1m821/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0866 - loss: 5.5423\n",
            "Epoch 6: loss improved from 5.70632 to 5.56343, saving model to weights-improvement-06-5.5634.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.0866 - loss: 5.5423\n",
            "Epoch 7/100\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0992 - loss: 5.3788\n",
            "Epoch 7: loss improved from 5.56343 to 5.41037, saving model to weights-improvement-07-5.4104.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.0992 - loss: 5.3789\n",
            "Epoch 8/100\n",
            "\u001b[1m821/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1128 - loss: 5.2174\n",
            "Epoch 8: loss improved from 5.41037 to 5.26509, saving model to weights-improvement-08-5.2651.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.1128 - loss: 5.2175\n",
            "Epoch 9/100\n",
            "\u001b[1m822/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1155 - loss: 5.1069\n",
            "Epoch 9: loss improved from 5.26509 to 5.13160, saving model to weights-improvement-09-5.1316.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.1155 - loss: 5.1069\n",
            "Epoch 10/100\n",
            "\u001b[1m822/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1247 - loss: 4.9793\n",
            "Epoch 10: loss improved from 5.13160 to 5.00109, saving model to weights-improvement-10-5.0011.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.1247 - loss: 4.9794\n",
            "Epoch 11/100\n",
            "\u001b[1m822/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1320 - loss: 4.8704\n",
            "Epoch 11: loss improved from 5.00109 to 4.87949, saving model to weights-improvement-11-4.8795.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.1320 - loss: 4.8704\n",
            "Epoch 12/100\n",
            "\u001b[1m821/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1404 - loss: 4.6876\n",
            "Epoch 12: loss improved from 4.87949 to 4.74759, saving model to weights-improvement-12-4.7476.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.1404 - loss: 4.6878\n",
            "Epoch 13/100\n",
            "\u001b[1m821/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1465 - loss: 4.5889\n",
            "Epoch 13: loss improved from 4.74759 to 4.62290, saving model to weights-improvement-13-4.6229.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.1465 - loss: 4.5890\n",
            "Epoch 14/100\n",
            "\u001b[1m819/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1482 - loss: 4.4786\n",
            "Epoch 14: loss improved from 4.62290 to 4.51047, saving model to weights-improvement-14-4.5105.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.1483 - loss: 4.4788\n",
            "Epoch 15/100\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1572 - loss: 4.3805\n",
            "Epoch 15: loss improved from 4.51047 to 4.38601, saving model to weights-improvement-15-4.3860.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.1572 - loss: 4.3805\n",
            "Epoch 16/100\n",
            "\u001b[1m819/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1640 - loss: 4.2639\n",
            "Epoch 16: loss improved from 4.38601 to 4.34731, saving model to weights-improvement-16-4.3473.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.1640 - loss: 4.2644\n",
            "Epoch 17/100\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1749 - loss: 4.1456\n",
            "Epoch 17: loss improved from 4.34731 to 4.17417, saving model to weights-improvement-17-4.1742.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.1749 - loss: 4.1457\n",
            "Epoch 18/100\n",
            "\u001b[1m822/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1802 - loss: 4.0440\n",
            "Epoch 18: loss improved from 4.17417 to 4.07286, saving model to weights-improvement-18-4.0729.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.1801 - loss: 4.0441\n",
            "Epoch 19/100\n",
            "\u001b[1m820/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1817 - loss: 3.9519\n",
            "Epoch 19: loss improved from 4.07286 to 3.97401, saving model to weights-improvement-19-3.9740.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.1817 - loss: 3.9520\n",
            "Epoch 20/100\n",
            "\u001b[1m822/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2023 - loss: 3.8176\n",
            "Epoch 20: loss improved from 3.97401 to 3.87082, saving model to weights-improvement-20-3.8708.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - accuracy: 0.2023 - loss: 3.8178\n",
            "Epoch 21/100\n",
            "\u001b[1m820/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2046 - loss: 3.7445\n",
            "Epoch 21: loss improved from 3.87082 to 3.77730, saving model to weights-improvement-21-3.7773.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.2045 - loss: 3.7447\n",
            "Epoch 22/100\n",
            "\u001b[1m822/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2097 - loss: 3.6307\n",
            "Epoch 22: loss improved from 3.77730 to 3.69075, saving model to weights-improvement-22-3.6907.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.2096 - loss: 3.6308\n",
            "Epoch 23/100\n",
            "\u001b[1m821/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2231 - loss: 3.5462\n",
            "Epoch 23: loss improved from 3.69075 to 3.60381, saving model to weights-improvement-23-3.6038.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.2231 - loss: 3.5464\n",
            "Epoch 24/100\n",
            "\u001b[1m820/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2315 - loss: 3.4699\n",
            "Epoch 24: loss improved from 3.60381 to 3.53244, saving model to weights-improvement-24-3.5324.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.2314 - loss: 3.4702\n",
            "Epoch 25/100\n",
            "\u001b[1m821/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2395 - loss: 3.3939\n",
            "Epoch 25: loss improved from 3.53244 to 3.44294, saving model to weights-improvement-25-3.4429.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.2395 - loss: 3.3940\n",
            "Epoch 26/100\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2519 - loss: 3.3228\n",
            "Epoch 26: loss improved from 3.44294 to 3.37151, saving model to weights-improvement-26-3.3715.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.2519 - loss: 3.3229\n",
            "Epoch 27/100\n",
            "\u001b[1m821/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2578 - loss: 3.2605\n",
            "Epoch 27: loss improved from 3.37151 to 3.29995, saving model to weights-improvement-27-3.2999.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.2578 - loss: 3.2607\n",
            "Epoch 28/100\n",
            "\u001b[1m820/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2650 - loss: 3.1930\n",
            "Epoch 28: loss improved from 3.29995 to 3.23530, saving model to weights-improvement-28-3.2353.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.2650 - loss: 3.1932\n",
            "Epoch 29/100\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2743 - loss: 3.1159\n",
            "Epoch 29: loss improved from 3.23530 to 3.16688, saving model to weights-improvement-29-3.1669.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.2743 - loss: 3.1160\n",
            "Epoch 30/100\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2891 - loss: 3.0501\n",
            "Epoch 30: loss improved from 3.16688 to 3.10996, saving model to weights-improvement-30-3.1100.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.2891 - loss: 3.0502\n",
            "Epoch 31/100\n",
            "\u001b[1m819/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2967 - loss: 2.9962\n",
            "Epoch 31: loss improved from 3.10996 to 3.05020, saving model to weights-improvement-31-3.0502.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.2966 - loss: 2.9966\n",
            "Epoch 32/100\n",
            "\u001b[1m819/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3080 - loss: 2.9363\n",
            "Epoch 32: loss improved from 3.05020 to 3.00456, saving model to weights-improvement-32-3.0046.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.3079 - loss: 2.9367\n",
            "Epoch 33/100\n",
            "\u001b[1m820/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3088 - loss: 2.8957\n",
            "Epoch 33: loss improved from 3.00456 to 2.94604, saving model to weights-improvement-33-2.9460.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.3088 - loss: 2.8959\n",
            "Epoch 34/100\n",
            "\u001b[1m820/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3257 - loss: 2.8261\n",
            "Epoch 34: loss improved from 2.94604 to 2.89677, saving model to weights-improvement-34-2.8968.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.3257 - loss: 2.8265\n",
            "Epoch 35/100\n",
            "\u001b[1m820/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3312 - loss: 2.8007\n",
            "Epoch 35: loss improved from 2.89677 to 2.86239, saving model to weights-improvement-35-2.8624.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.3312 - loss: 2.8010\n",
            "Epoch 36/100\n",
            "\u001b[1m820/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3401 - loss: 2.7346\n",
            "Epoch 36: loss improved from 2.86239 to 2.79163, saving model to weights-improvement-36-2.7916.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.3400 - loss: 2.7349\n",
            "Epoch 37/100\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3485 - loss: 2.6746\n",
            "Epoch 37: loss improved from 2.79163 to 2.74361, saving model to weights-improvement-37-2.7436.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.3484 - loss: 2.6746\n",
            "Epoch 38/100\n",
            "\u001b[1m821/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3538 - loss: 2.6624\n",
            "Epoch 38: loss improved from 2.74361 to 2.70396, saving model to weights-improvement-38-2.7040.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.3538 - loss: 2.6626\n",
            "Epoch 39/100\n",
            "\u001b[1m820/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3582 - loss: 2.6205\n",
            "Epoch 39: loss improved from 2.70396 to 2.66588, saving model to weights-improvement-39-2.6659.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.3581 - loss: 2.6207\n",
            "Epoch 40/100\n",
            "\u001b[1m820/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3660 - loss: 2.5657\n",
            "Epoch 40: loss improved from 2.66588 to 2.62138, saving model to weights-improvement-40-2.6214.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.3660 - loss: 2.5660\n",
            "Epoch 41/100\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3761 - loss: 2.5198\n",
            "Epoch 41: loss improved from 2.62138 to 2.57772, saving model to weights-improvement-41-2.5777.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.3761 - loss: 2.5199\n",
            "Epoch 42/100\n",
            "\u001b[1m820/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3744 - loss: 2.5102\n",
            "Epoch 42: loss improved from 2.57772 to 2.54496, saving model to weights-improvement-42-2.5450.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.3744 - loss: 2.5103\n",
            "Epoch 43/100\n",
            "\u001b[1m821/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3867 - loss: 2.4572\n",
            "Epoch 43: loss improved from 2.54496 to 2.50989, saving model to weights-improvement-43-2.5099.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.3866 - loss: 2.4574\n",
            "Epoch 44/100\n",
            "\u001b[1m820/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3948 - loss: 2.4180\n",
            "Epoch 44: loss improved from 2.50989 to 2.47355, saving model to weights-improvement-44-2.4735.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.3948 - loss: 2.4183\n",
            "Epoch 45/100\n",
            "\u001b[1m821/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3988 - loss: 2.3881\n",
            "Epoch 45: loss improved from 2.47355 to 2.43934, saving model to weights-improvement-45-2.4393.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.3987 - loss: 2.3883\n",
            "Epoch 46/100\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4096 - loss: 2.3536\n",
            "Epoch 46: loss improved from 2.43934 to 2.40801, saving model to weights-improvement-46-2.4080.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.4096 - loss: 2.3536\n",
            "Epoch 47/100\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4128 - loss: 2.3250\n",
            "Epoch 47: loss improved from 2.40801 to 2.36608, saving model to weights-improvement-47-2.3661.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.4128 - loss: 2.3251\n",
            "Epoch 48/100\n",
            "\u001b[1m822/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4209 - loss: 2.2833\n",
            "Epoch 48: loss improved from 2.36608 to 2.33422, saving model to weights-improvement-48-2.3342.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.4208 - loss: 2.2834\n",
            "Epoch 49/100\n",
            "\u001b[1m822/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4293 - loss: 2.2500\n",
            "Epoch 49: loss improved from 2.33422 to 2.30603, saving model to weights-improvement-49-2.3060.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.4292 - loss: 2.2502\n",
            "Epoch 50/100\n",
            "\u001b[1m822/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4337 - loss: 2.2189\n",
            "Epoch 50: loss improved from 2.30603 to 2.28035, saving model to weights-improvement-50-2.2804.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.4336 - loss: 2.2190\n",
            "Epoch 51/100\n",
            "\u001b[1m820/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4323 - loss: 2.2076\n",
            "Epoch 51: loss improved from 2.28035 to 2.24824, saving model to weights-improvement-51-2.2482.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.4323 - loss: 2.2078\n",
            "Epoch 52/100\n",
            "\u001b[1m820/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4357 - loss: 2.1892\n",
            "Epoch 52: loss improved from 2.24824 to 2.21835, saving model to weights-improvement-52-2.2184.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.4356 - loss: 2.1894\n",
            "Epoch 53/100\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4510 - loss: 2.1473\n",
            "Epoch 53: loss improved from 2.21835 to 2.20544, saving model to weights-improvement-53-2.2054.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.4509 - loss: 2.1473\n",
            "Epoch 54/100\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4534 - loss: 2.1258\n",
            "Epoch 54: loss improved from 2.20544 to 2.17218, saving model to weights-improvement-54-2.1722.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.4534 - loss: 2.1259\n",
            "Epoch 55/100\n",
            "\u001b[1m821/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4615 - loss: 2.0812\n",
            "Epoch 55: loss improved from 2.17218 to 2.13512, saving model to weights-improvement-55-2.1351.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.4614 - loss: 2.0814\n",
            "Epoch 56/100\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4714 - loss: 2.0748\n",
            "Epoch 56: loss did not improve from 2.13512\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.4714 - loss: 2.0749\n",
            "Epoch 57/100\n",
            "\u001b[1m820/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4542 - loss: 2.0873\n",
            "Epoch 57: loss improved from 2.13512 to 2.11265, saving model to weights-improvement-57-2.1126.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.4542 - loss: 2.0874\n",
            "Epoch 58/100\n",
            "\u001b[1m820/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4727 - loss: 2.0360\n",
            "Epoch 58: loss improved from 2.11265 to 2.07353, saving model to weights-improvement-58-2.0735.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.4727 - loss: 2.0361\n",
            "Epoch 59/100\n",
            "\u001b[1m820/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4759 - loss: 1.9958\n",
            "Epoch 59: loss improved from 2.07353 to 2.02481, saving model to weights-improvement-59-2.0248.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.4759 - loss: 1.9959\n",
            "Epoch 60/100\n",
            "\u001b[1m821/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4860 - loss: 1.9669\n",
            "Epoch 60: loss improved from 2.02481 to 2.00695, saving model to weights-improvement-60-2.0069.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.4860 - loss: 1.9670\n",
            "Epoch 61/100\n",
            "\u001b[1m820/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4896 - loss: 1.9443\n",
            "Epoch 61: loss improved from 2.00695 to 1.98561, saving model to weights-improvement-61-1.9856.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.4895 - loss: 1.9445\n",
            "Epoch 62/100\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4960 - loss: 1.9154\n",
            "Epoch 62: loss improved from 1.98561 to 1.96634, saving model to weights-improvement-62-1.9663.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.4959 - loss: 1.9155\n",
            "Epoch 63/100\n",
            "\u001b[1m820/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4950 - loss: 1.8970\n",
            "Epoch 63: loss improved from 1.96634 to 1.94840, saving model to weights-improvement-63-1.9484.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.4950 - loss: 1.8973\n",
            "Epoch 64/100\n",
            "\u001b[1m819/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5061 - loss: 1.8739\n",
            "Epoch 64: loss improved from 1.94840 to 1.93298, saving model to weights-improvement-64-1.9330.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.5060 - loss: 1.8742\n",
            "Epoch 65/100\n",
            "\u001b[1m820/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5024 - loss: 1.8766\n",
            "Epoch 65: loss improved from 1.93298 to 1.91437, saving model to weights-improvement-65-1.9144.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.5023 - loss: 1.8768\n",
            "Epoch 66/100\n",
            "\u001b[1m822/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5103 - loss: 1.8484\n",
            "Epoch 66: loss improved from 1.91437 to 1.88079, saving model to weights-improvement-66-1.8808.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.5103 - loss: 1.8485\n",
            "Epoch 67/100\n",
            "\u001b[1m822/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5148 - loss: 1.8378\n",
            "Epoch 67: loss improved from 1.88079 to 1.88065, saving model to weights-improvement-67-1.8807.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.5147 - loss: 1.8379\n",
            "Epoch 68/100\n",
            "\u001b[1m821/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5121 - loss: 1.8374\n",
            "Epoch 68: loss improved from 1.88065 to 1.87485, saving model to weights-improvement-68-1.8749.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.5121 - loss: 1.8375\n",
            "Epoch 69/100\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5117 - loss: 1.8186\n",
            "Epoch 69: loss improved from 1.87485 to 1.85966, saving model to weights-improvement-69-1.8597.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.5117 - loss: 1.8186\n",
            "Epoch 70/100\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5199 - loss: 1.8053\n",
            "Epoch 70: loss improved from 1.85966 to 1.84561, saving model to weights-improvement-70-1.8456.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.5199 - loss: 1.8054\n",
            "Epoch 71/100\n",
            "\u001b[1m822/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5196 - loss: 1.7881\n",
            "Epoch 71: loss improved from 1.84561 to 1.82471, saving model to weights-improvement-71-1.8247.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.5196 - loss: 1.7882\n",
            "Epoch 72/100\n",
            "\u001b[1m819/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5234 - loss: 1.7669\n",
            "Epoch 72: loss improved from 1.82471 to 1.80702, saving model to weights-improvement-72-1.8070.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.5234 - loss: 1.7672\n",
            "Epoch 73/100\n",
            "\u001b[1m820/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5263 - loss: 1.7589\n",
            "Epoch 73: loss improved from 1.80702 to 1.80205, saving model to weights-improvement-73-1.8020.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 11ms/step - accuracy: 0.5262 - loss: 1.7591\n",
            "Epoch 74/100\n",
            "\u001b[1m822/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5421 - loss: 1.7214\n",
            "Epoch 74: loss improved from 1.80205 to 1.76538, saving model to weights-improvement-74-1.7654.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.5421 - loss: 1.7215\n",
            "Epoch 75/100\n",
            "\u001b[1m822/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5310 - loss: 1.7285\n",
            "Epoch 75: loss improved from 1.76538 to 1.76193, saving model to weights-improvement-75-1.7619.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.5309 - loss: 1.7285\n",
            "Epoch 76/100\n",
            "\u001b[1m820/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5415 - loss: 1.6960\n",
            "Epoch 76: loss improved from 1.76193 to 1.73520, saving model to weights-improvement-76-1.7352.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.5414 - loss: 1.6962\n",
            "Epoch 77/100\n",
            "\u001b[1m820/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5527 - loss: 1.6710\n",
            "Epoch 77: loss did not improve from 1.73520\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.5526 - loss: 1.6714\n",
            "Epoch 78/100\n",
            "\u001b[1m821/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5465 - loss: 1.6775\n",
            "Epoch 78: loss improved from 1.73520 to 1.71446, saving model to weights-improvement-78-1.7145.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.5465 - loss: 1.6777\n",
            "Epoch 79/100\n",
            "\u001b[1m822/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5502 - loss: 1.6652\n",
            "Epoch 79: loss improved from 1.71446 to 1.70473, saving model to weights-improvement-79-1.7047.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.5501 - loss: 1.6653\n",
            "Epoch 80/100\n",
            "\u001b[1m820/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5511 - loss: 1.6451\n",
            "Epoch 80: loss improved from 1.70473 to 1.67752, saving model to weights-improvement-80-1.6775.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.5510 - loss: 1.6453\n",
            "Epoch 81/100\n",
            "\u001b[1m821/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5532 - loss: 1.6310\n",
            "Epoch 81: loss did not improve from 1.67752\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.5531 - loss: 1.6312\n",
            "Epoch 82/100\n",
            "\u001b[1m822/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5535 - loss: 1.6346\n",
            "Epoch 82: loss improved from 1.67752 to 1.65600, saving model to weights-improvement-82-1.6560.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.5535 - loss: 1.6346\n",
            "Epoch 83/100\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5621 - loss: 1.5905\n",
            "Epoch 83: loss improved from 1.65600 to 1.64093, saving model to weights-improvement-83-1.6409.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.5621 - loss: 1.5906\n",
            "Epoch 84/100\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5663 - loss: 1.5835\n",
            "Epoch 84: loss improved from 1.64093 to 1.62227, saving model to weights-improvement-84-1.6223.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.5663 - loss: 1.5835\n",
            "Epoch 85/100\n",
            "\u001b[1m822/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5700 - loss: 1.5734\n",
            "Epoch 85: loss improved from 1.62227 to 1.61402, saving model to weights-improvement-85-1.6140.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.5700 - loss: 1.5735\n",
            "Epoch 86/100\n",
            "\u001b[1m819/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5769 - loss: 1.5403\n",
            "Epoch 86: loss improved from 1.61402 to 1.58944, saving model to weights-improvement-86-1.5894.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.5768 - loss: 1.5406\n",
            "Epoch 87/100\n",
            "\u001b[1m820/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5756 - loss: 1.5330\n",
            "Epoch 87: loss improved from 1.58944 to 1.58423, saving model to weights-improvement-87-1.5842.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.5755 - loss: 1.5332\n",
            "Epoch 88/100\n",
            "\u001b[1m819/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5719 - loss: 1.5540\n",
            "Epoch 88: loss improved from 1.58423 to 1.58122, saving model to weights-improvement-88-1.5812.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.5719 - loss: 1.5542\n",
            "Epoch 89/100\n",
            "\u001b[1m819/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5825 - loss: 1.5205\n",
            "Epoch 89: loss improved from 1.58122 to 1.56613, saving model to weights-improvement-89-1.5661.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.5824 - loss: 1.5207\n",
            "Epoch 90/100\n",
            "\u001b[1m820/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5826 - loss: 1.5205\n",
            "Epoch 90: loss improved from 1.56613 to 1.55281, saving model to weights-improvement-90-1.5528.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.5826 - loss: 1.5207\n",
            "Epoch 91/100\n",
            "\u001b[1m822/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5848 - loss: 1.4985\n",
            "Epoch 91: loss improved from 1.55281 to 1.54190, saving model to weights-improvement-91-1.5419.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.5848 - loss: 1.4986\n",
            "Epoch 92/100\n",
            "\u001b[1m820/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5854 - loss: 1.4835\n",
            "Epoch 92: loss improved from 1.54190 to 1.52367, saving model to weights-improvement-92-1.5237.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.5854 - loss: 1.4837\n",
            "Epoch 93/100\n",
            "\u001b[1m819/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5947 - loss: 1.4623\n",
            "Epoch 93: loss improved from 1.52367 to 1.52131, saving model to weights-improvement-93-1.5213.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.5946 - loss: 1.4627\n",
            "Epoch 94/100\n",
            "\u001b[1m820/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5925 - loss: 1.4658\n",
            "Epoch 94: loss improved from 1.52131 to 1.50463, saving model to weights-improvement-94-1.5046.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.5925 - loss: 1.4660\n",
            "Epoch 95/100\n",
            "\u001b[1m820/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5964 - loss: 1.4468\n",
            "Epoch 95: loss improved from 1.50463 to 1.48951, saving model to weights-improvement-95-1.4895.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.5964 - loss: 1.4470\n",
            "Epoch 96/100\n",
            "\u001b[1m821/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5948 - loss: 1.4444\n",
            "Epoch 96: loss improved from 1.48951 to 1.47898, saving model to weights-improvement-96-1.4790.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5948 - loss: 1.4446\n",
            "Epoch 97/100\n",
            "\u001b[1m821/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6115 - loss: 1.4130\n",
            "Epoch 97: loss improved from 1.47898 to 1.46786, saving model to weights-improvement-97-1.4679.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.6114 - loss: 1.4132\n",
            "Epoch 98/100\n",
            "\u001b[1m821/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5980 - loss: 1.4291\n",
            "Epoch 98: loss did not improve from 1.46786\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5980 - loss: 1.4292\n",
            "Epoch 99/100\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6046 - loss: 1.4199\n",
            "Epoch 99: loss improved from 1.46786 to 1.45373, saving model to weights-improvement-99-1.4537.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.6045 - loss: 1.4199\n",
            "Epoch 100/100\n",
            "\u001b[1m822/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6023 - loss: 1.4117\n",
            "Epoch 100: loss improved from 1.45373 to 1.43366, saving model to weights-improvement-100-1.4337.keras\n",
            "\u001b[1m823/823\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.6023 - loss: 1.4118\n",
            "Model telah disimpan sebagai 'trained_model.keras'\n",
            "Files found: ['weights-improvement-11-4.8795.keras', 'weights-improvement-09-5.1316.keras', 'weights-improvement-52-2.2184.keras', 'weights-improvement-26-3.3715.keras', 'weights-improvement-03-5.9974.keras', 'weights-improvement-10-5.0011.keras', 'weights-improvement-44-2.4735.keras', 'weights-improvement-93-1.5213.keras', 'weights-improvement-51-2.2482.keras', 'weights-improvement-27-3.2999.keras', 'weights-improvement-86-1.5894.keras', 'weights-improvement-25-3.4429.keras', 'weights-improvement-64-1.9330.keras', 'weights-improvement-82-1.6560.keras', 'weights-improvement-57-2.1126.keras', 'weights-improvement-12-4.7476.keras', 'weights-improvement-45-2.4393.keras', 'weights-improvement-33-2.9460.keras', 'weights-improvement-04-5.8480.keras', 'weights-improvement-13-4.6229.keras', 'weights-improvement-43-2.5099.keras', 'weights-improvement-79-1.7047.keras', 'weights-improvement-90-1.5528.keras', 'weights-improvement-41-2.5777.keras', 'weights-improvement-60-2.0069.keras', 'weights-improvement-16-4.3473.keras', 'weights-improvement-32-3.0046.keras', 'weights-improvement-96-1.4790.keras', 'weights-improvement-28-3.2353.keras', 'weights-improvement-87-1.5842.keras', 'weights-improvement-78-1.7145.keras', 'weights-improvement-29-3.1669.keras', 'weights-improvement-21-3.7773.keras', 'weights-improvement-75-1.7619.keras', 'weights-improvement-22-3.6907.keras', 'weights-improvement-97-1.4679.keras', 'weights-improvement-71-1.8247.keras', 'weights-improvement-06-5.5634.keras', 'weights-improvement-72-1.8070.keras', 'weights-improvement-59-2.0248.keras', 'weights-improvement-02-6.1594.keras', 'weights-improvement-39-2.6659.keras', 'weights-improvement-95-1.4895.keras', 'weights-improvement-50-2.2804.keras', 'weights-improvement-62-1.9663.keras', 'weights-improvement-23-3.6038.keras', 'weights-improvement-85-1.6140.keras', 'weights-improvement-88-1.5812.keras', 'weights-improvement-17-4.1742.keras', 'weights-improvement-65-1.9144.keras', 'trained_model.keras', 'weights-improvement-61-1.9856.keras', 'weights-improvement-38-2.7040.keras', 'weights-improvement-01-6.4564.keras', 'weights-improvement-14-4.5105.keras', 'weights-improvement-31-3.0502.keras', 'weights-improvement-63-1.9484.keras', 'weights-improvement-15-4.3860.keras', 'weights-improvement-35-2.8624.keras', 'weights-improvement-30-3.1100.keras', 'weights-improvement-70-1.8456.keras', 'weights-improvement-07-5.4104.keras', 'weights-improvement-92-1.5237.keras', 'weights-improvement-19-3.9740.keras', 'weights-improvement-58-2.0735.keras', 'weights-improvement-54-2.1722.keras', 'weights-improvement-84-1.6223.keras', 'weights-improvement-76-1.7352.keras', 'weights-improvement-91-1.5419.keras', 'weights-improvement-49-2.3060.keras', 'weights-improvement-73-1.8020.keras', 'weights-improvement-36-2.7916.keras', 'weights-improvement-67-1.8807.keras', 'weights-improvement-74-1.7654.keras', 'weights-improvement-24-3.5324.keras', 'weights-improvement-05-5.7063.keras', 'weights-improvement-99-1.4537.keras', 'weights-improvement-68-1.8749.keras', 'weights-improvement-42-2.5450.keras', 'weights-improvement-08-5.2651.keras', 'weights-improvement-47-2.3661.keras', 'weights-improvement-66-1.8808.keras', 'weights-improvement-89-1.5661.keras', 'weights-improvement-18-4.0729.keras', 'weights-improvement-55-2.1351.keras', 'weights-improvement-69-1.8597.keras', 'weights-improvement-53-2.2054.keras', 'weights-improvement-48-2.3342.keras', 'weights-improvement-37-2.7436.keras', 'weights-improvement-40-2.6214.keras', 'weights-improvement-80-1.6775.keras', 'weights-improvement-94-1.5046.keras', 'weights-improvement-20-3.8708.keras', 'weights-improvement-100-1.4337.keras', 'weights-improvement-83-1.6409.keras', 'weights-improvement-34-2.8968.keras', 'weights-improvement-46-2.4080.keras']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "epochs = 100  # Increased epochs\n",
        "batch_size = 64  # Experiment with different batch sizes\n",
        "model.fit(X, y, epochs=epochs, batch_size=batch_size, callbacks=callbacks_list)\n",
        "\n",
        "# Menyimpan model yang telah dilatih\n",
        "model.save(\"trained_model.keras\")\n",
        "print(\"Model telah disimpan sebagai 'trained_model.keras'\")\n",
        "\n",
        "# Menampilkan file .keras di direktori kerja\n",
        "files = [f for f in os.listdir() if f.endswith('.keras')]\n",
        "print(\"Files found:\", files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2hP3s1vhE7y",
        "outputId": "8da57fca-86d8-4511-fba4-02c1f31601c1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6234 - loss: 1.3452\n",
            "Epoch 1: loss improved from 1.43366 to 1.33580, saving model to weights-improvement-01-1.3358.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.6234 - loss: 1.3451\n",
            "Epoch 2/100\n",
            "\u001b[1m411/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6357 - loss: 1.2688\n",
            "Epoch 2: loss improved from 1.33580 to 1.29972, saving model to weights-improvement-02-1.2997.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.6357 - loss: 1.2689\n",
            "Epoch 3/100\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6452 - loss: 1.2590\n",
            "Epoch 3: loss improved from 1.29972 to 1.28816, saving model to weights-improvement-03-1.2882.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.6452 - loss: 1.2590\n",
            "Epoch 4/100\n",
            "\u001b[1m411/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6420 - loss: 1.2579\n",
            "Epoch 4: loss improved from 1.28816 to 1.27907, saving model to weights-improvement-04-1.2791.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.6420 - loss: 1.2580\n",
            "Epoch 5/100\n",
            "\u001b[1m410/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6421 - loss: 1.2628\n",
            "Epoch 5: loss improved from 1.27907 to 1.27298, saving model to weights-improvement-05-1.2730.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.6420 - loss: 1.2629\n",
            "Epoch 6/100\n",
            "\u001b[1m411/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6450 - loss: 1.2483\n",
            "Epoch 6: loss did not improve from 1.27298\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.6450 - loss: 1.2485\n",
            "Epoch 7/100\n",
            "\u001b[1m411/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6492 - loss: 1.2380\n",
            "Epoch 7: loss did not improve from 1.27298\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.6492 - loss: 1.2382\n",
            "Epoch 8/100\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6497 - loss: 1.2328\n",
            "Epoch 8: loss improved from 1.27298 to 1.26505, saving model to weights-improvement-08-1.2651.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.6497 - loss: 1.2328\n",
            "Epoch 9/100\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6486 - loss: 1.2326\n",
            "Epoch 9: loss improved from 1.26505 to 1.26348, saving model to weights-improvement-09-1.2635.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.6485 - loss: 1.2326\n",
            "Epoch 10/100\n",
            "\u001b[1m409/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6557 - loss: 1.2107\n",
            "Epoch 10: loss improved from 1.26348 to 1.25208, saving model to weights-improvement-10-1.2521.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.6556 - loss: 1.2111\n",
            "Epoch 11/100\n",
            "\u001b[1m410/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6572 - loss: 1.1977\n",
            "Epoch 11: loss improved from 1.25208 to 1.23766, saving model to weights-improvement-11-1.2377.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.6571 - loss: 1.1980\n",
            "Epoch 12/100\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6561 - loss: 1.2116\n",
            "Epoch 12: loss did not improve from 1.23766\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.6561 - loss: 1.2117\n",
            "Epoch 13/100\n",
            "\u001b[1m410/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6554 - loss: 1.2038\n",
            "Epoch 13: loss improved from 1.23766 to 1.22376, saving model to weights-improvement-13-1.2238.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.6554 - loss: 1.2039\n",
            "Epoch 14/100\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6506 - loss: 1.2054\n",
            "Epoch 14: loss did not improve from 1.22376\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.6506 - loss: 1.2054\n",
            "Epoch 15/100\n",
            "\u001b[1m411/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6630 - loss: 1.1879\n",
            "Epoch 15: loss improved from 1.22376 to 1.21200, saving model to weights-improvement-15-1.2120.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.6629 - loss: 1.1880\n",
            "Epoch 16/100\n",
            "\u001b[1m410/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6630 - loss: 1.1838\n",
            "Epoch 16: loss did not improve from 1.21200\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.6629 - loss: 1.1841\n",
            "Epoch 17/100\n",
            "\u001b[1m411/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6585 - loss: 1.1970\n",
            "Epoch 17: loss improved from 1.21200 to 1.21160, saving model to weights-improvement-17-1.2116.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.6585 - loss: 1.1971\n",
            "Epoch 18/100\n",
            "\u001b[1m409/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6646 - loss: 1.1683\n",
            "Epoch 18: loss improved from 1.21160 to 1.19463, saving model to weights-improvement-18-1.1946.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.6645 - loss: 1.1686\n",
            "Epoch 19/100\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6617 - loss: 1.1739\n",
            "Epoch 19: loss improved from 1.19463 to 1.19063, saving model to weights-improvement-19-1.1906.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.6617 - loss: 1.1740\n",
            "Epoch 20/100\n",
            "\u001b[1m411/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6639 - loss: 1.1802\n",
            "Epoch 20: loss improved from 1.19063 to 1.19060, saving model to weights-improvement-20-1.1906.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.6639 - loss: 1.1802\n",
            "Epoch 21/100\n",
            "\u001b[1m409/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6690 - loss: 1.1613\n",
            "Epoch 21: loss improved from 1.19060 to 1.18471, saving model to weights-improvement-21-1.1847.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.6689 - loss: 1.1616\n",
            "Epoch 22/100\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6716 - loss: 1.1444\n",
            "Epoch 22: loss improved from 1.18471 to 1.16757, saving model to weights-improvement-22-1.1676.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.6716 - loss: 1.1445\n",
            "Epoch 23/100\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6724 - loss: 1.1395\n",
            "Epoch 23: loss improved from 1.16757 to 1.15804, saving model to weights-improvement-23-1.1580.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.6724 - loss: 1.1396\n",
            "Epoch 24/100\n",
            "\u001b[1m409/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6746 - loss: 1.1270\n",
            "Epoch 24: loss improved from 1.15804 to 1.14310, saving model to weights-improvement-24-1.1431.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.6745 - loss: 1.1271\n",
            "Epoch 25/100\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6752 - loss: 1.1287\n",
            "Epoch 25: loss did not improve from 1.14310\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.6752 - loss: 1.1287\n",
            "Epoch 26/100\n",
            "\u001b[1m411/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6792 - loss: 1.1017\n",
            "Epoch 26: loss improved from 1.14310 to 1.13922, saving model to weights-improvement-26-1.1392.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.6792 - loss: 1.1019\n",
            "Epoch 27/100\n",
            "\u001b[1m410/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6755 - loss: 1.1083\n",
            "Epoch 27: loss did not improve from 1.13922\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.6754 - loss: 1.1086\n",
            "Epoch 28/100\n",
            "\u001b[1m409/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6796 - loss: 1.1204\n",
            "Epoch 28: loss did not improve from 1.13922\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.6796 - loss: 1.1207\n",
            "Epoch 29/100\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6798 - loss: 1.1087\n",
            "Epoch 29: loss improved from 1.13922 to 1.12065, saving model to weights-improvement-29-1.1207.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.6798 - loss: 1.1087\n",
            "Epoch 30/100\n",
            "\u001b[1m409/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6888 - loss: 1.0763\n",
            "Epoch 30: loss improved from 1.12065 to 1.10764, saving model to weights-improvement-30-1.1076.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.6887 - loss: 1.0766\n",
            "Epoch 31/100\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6891 - loss: 1.0749\n",
            "Epoch 31: loss improved from 1.10764 to 1.09909, saving model to weights-improvement-31-1.0991.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.6890 - loss: 1.0749\n",
            "Epoch 32/100\n",
            "\u001b[1m409/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6883 - loss: 1.0537\n",
            "Epoch 32: loss improved from 1.09909 to 1.09282, saving model to weights-improvement-32-1.0928.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.6882 - loss: 1.0541\n",
            "Epoch 33/100\n",
            "\u001b[1m409/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6933 - loss: 1.0634\n",
            "Epoch 33: loss improved from 1.09282 to 1.08910, saving model to weights-improvement-33-1.0891.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.6932 - loss: 1.0636\n",
            "Epoch 34/100\n",
            "\u001b[1m410/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6947 - loss: 1.0414\n",
            "Epoch 34: loss improved from 1.08910 to 1.07211, saving model to weights-improvement-34-1.0721.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.6946 - loss: 1.0416\n",
            "Epoch 35/100\n",
            "\u001b[1m409/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6966 - loss: 1.0549\n",
            "Epoch 35: loss did not improve from 1.07211\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.6965 - loss: 1.0551\n",
            "Epoch 36/100\n",
            "\u001b[1m411/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6994 - loss: 1.0330\n",
            "Epoch 36: loss improved from 1.07211 to 1.06900, saving model to weights-improvement-36-1.0690.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.6994 - loss: 1.0332\n",
            "Epoch 37/100\n",
            "\u001b[1m411/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6992 - loss: 1.0549\n",
            "Epoch 37: loss did not improve from 1.06900\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.6991 - loss: 1.0550\n",
            "Epoch 38/100\n",
            "\u001b[1m411/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6959 - loss: 1.0404\n",
            "Epoch 38: loss improved from 1.06900 to 1.06465, saving model to weights-improvement-38-1.0646.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.6959 - loss: 1.0405\n",
            "Epoch 39/100\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6974 - loss: 1.0338\n",
            "Epoch 39: loss improved from 1.06465 to 1.06429, saving model to weights-improvement-39-1.0643.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.6974 - loss: 1.0338\n",
            "Epoch 40/100\n",
            "\u001b[1m411/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6935 - loss: 1.0511\n",
            "Epoch 40: loss did not improve from 1.06429\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.6935 - loss: 1.0512\n",
            "Epoch 41/100\n",
            "\u001b[1m411/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6943 - loss: 1.0481\n",
            "Epoch 41: loss improved from 1.06429 to 1.05390, saving model to weights-improvement-41-1.0539.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.6943 - loss: 1.0481\n",
            "Epoch 42/100\n",
            "\u001b[1m410/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7028 - loss: 1.0122\n",
            "Epoch 42: loss improved from 1.05390 to 1.04580, saving model to weights-improvement-42-1.0458.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.7028 - loss: 1.0124\n",
            "Epoch 43/100\n",
            "\u001b[1m411/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7035 - loss: 1.0130\n",
            "Epoch 43: loss improved from 1.04580 to 1.04035, saving model to weights-improvement-43-1.0404.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.7035 - loss: 1.0131\n",
            "Epoch 44/100\n",
            "\u001b[1m411/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7000 - loss: 1.0123\n",
            "Epoch 44: loss improved from 1.04035 to 1.03384, saving model to weights-improvement-44-1.0338.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - accuracy: 0.7000 - loss: 1.0124\n",
            "Epoch 45/100\n",
            "\u001b[1m409/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7044 - loss: 0.9988\n",
            "Epoch 45: loss improved from 1.03384 to 1.03134, saving model to weights-improvement-45-1.0313.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.7044 - loss: 0.9991\n",
            "Epoch 46/100\n",
            "\u001b[1m411/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7055 - loss: 0.9986\n",
            "Epoch 46: loss improved from 1.03134 to 1.02294, saving model to weights-improvement-46-1.0229.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.7055 - loss: 0.9987\n",
            "Epoch 47/100\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7060 - loss: 0.9981\n",
            "Epoch 47: loss improved from 1.02294 to 1.02163, saving model to weights-improvement-47-1.0216.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7060 - loss: 0.9982\n",
            "Epoch 48/100\n",
            "\u001b[1m410/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7016 - loss: 0.9978\n",
            "Epoch 48: loss did not improve from 1.02163\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.7016 - loss: 0.9980\n",
            "Epoch 49/100\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7102 - loss: 0.9895\n",
            "Epoch 49: loss did not improve from 1.02163\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.7102 - loss: 0.9896\n",
            "Epoch 50/100\n",
            "\u001b[1m409/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7074 - loss: 0.9896\n",
            "Epoch 50: loss improved from 1.02163 to 1.00880, saving model to weights-improvement-50-1.0088.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7073 - loss: 0.9898\n",
            "Epoch 51/100\n",
            "\u001b[1m409/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7101 - loss: 0.9859\n",
            "Epoch 51: loss did not improve from 1.00880\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.7100 - loss: 0.9861\n",
            "Epoch 52/100\n",
            "\u001b[1m410/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7148 - loss: 0.9772\n",
            "Epoch 52: loss improved from 1.00880 to 0.99060, saving model to weights-improvement-52-0.9906.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.7148 - loss: 0.9772\n",
            "Epoch 53/100\n",
            "\u001b[1m411/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7150 - loss: 0.9676\n",
            "Epoch 53: loss did not improve from 0.99060\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.7150 - loss: 0.9677\n",
            "Epoch 54/100\n",
            "\u001b[1m411/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7177 - loss: 0.9507\n",
            "Epoch 54: loss improved from 0.99060 to 0.99022, saving model to weights-improvement-54-0.9902.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.7176 - loss: 0.9509\n",
            "Epoch 55/100\n",
            "\u001b[1m410/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7179 - loss: 0.9559\n",
            "Epoch 55: loss improved from 0.99022 to 0.98290, saving model to weights-improvement-55-0.9829.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.7178 - loss: 0.9561\n",
            "Epoch 56/100\n",
            "\u001b[1m410/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7162 - loss: 0.9594\n",
            "Epoch 56: loss did not improve from 0.98290\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.7161 - loss: 0.9597\n",
            "Epoch 57/100\n",
            "\u001b[1m411/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7173 - loss: 0.9593\n",
            "Epoch 57: loss improved from 0.98290 to 0.97099, saving model to weights-improvement-57-0.9710.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.7173 - loss: 0.9594\n",
            "Epoch 58/100\n",
            "\u001b[1m411/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7146 - loss: 0.9558\n",
            "Epoch 58: loss did not improve from 0.97099\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.7146 - loss: 0.9559\n",
            "Epoch 59/100\n",
            "\u001b[1m410/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7232 - loss: 0.9346\n",
            "Epoch 59: loss improved from 0.97099 to 0.96197, saving model to weights-improvement-59-0.9620.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.7232 - loss: 0.9348\n",
            "Epoch 60/100\n",
            "\u001b[1m410/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7232 - loss: 0.9409\n",
            "Epoch 60: loss did not improve from 0.96197\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.7232 - loss: 0.9411\n",
            "Epoch 61/100\n",
            "\u001b[1m409/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7205 - loss: 0.9378\n",
            "Epoch 61: loss improved from 0.96197 to 0.95791, saving model to weights-improvement-61-0.9579.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.7205 - loss: 0.9380\n",
            "Epoch 62/100\n",
            "\u001b[1m411/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7273 - loss: 0.9218\n",
            "Epoch 62: loss improved from 0.95791 to 0.94830, saving model to weights-improvement-62-0.9483.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.7273 - loss: 0.9219\n",
            "Epoch 63/100\n",
            "\u001b[1m409/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7244 - loss: 0.9248\n",
            "Epoch 63: loss improved from 0.94830 to 0.93836, saving model to weights-improvement-63-0.9384.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.7243 - loss: 0.9250\n",
            "Epoch 64/100\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7259 - loss: 0.9158\n",
            "Epoch 64: loss did not improve from 0.93836\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.7258 - loss: 0.9158\n",
            "Epoch 65/100\n",
            "\u001b[1m410/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7269 - loss: 0.9199\n",
            "Epoch 65: loss improved from 0.93836 to 0.93755, saving model to weights-improvement-65-0.9376.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.7269 - loss: 0.9200\n",
            "Epoch 66/100\n",
            "\u001b[1m409/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7246 - loss: 0.9196\n",
            "Epoch 66: loss improved from 0.93755 to 0.93513, saving model to weights-improvement-66-0.9351.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.7245 - loss: 0.9198\n",
            "Epoch 67/100\n",
            "\u001b[1m409/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7303 - loss: 0.9112\n",
            "Epoch 67: loss improved from 0.93513 to 0.92964, saving model to weights-improvement-67-0.9296.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.7302 - loss: 0.9114\n",
            "Epoch 68/100\n",
            "\u001b[1m409/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7336 - loss: 0.8982\n",
            "Epoch 68: loss improved from 0.92964 to 0.92633, saving model to weights-improvement-68-0.9263.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.7336 - loss: 0.8985\n",
            "Epoch 69/100\n",
            "\u001b[1m410/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7258 - loss: 0.9066\n",
            "Epoch 69: loss did not improve from 0.92633\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.7258 - loss: 0.9068\n",
            "Epoch 70/100\n",
            "\u001b[1m409/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7354 - loss: 0.8855\n",
            "Epoch 70: loss improved from 0.92633 to 0.90554, saving model to weights-improvement-70-0.9055.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.7354 - loss: 0.8857\n",
            "Epoch 71/100\n",
            "\u001b[1m409/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7341 - loss: 0.8806\n",
            "Epoch 71: loss did not improve from 0.90554\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.7340 - loss: 0.8809\n",
            "Epoch 72/100\n",
            "\u001b[1m411/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7346 - loss: 0.8907\n",
            "Epoch 72: loss did not improve from 0.90554\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.7345 - loss: 0.8908\n",
            "Epoch 73/100\n",
            "\u001b[1m410/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7346 - loss: 0.8806\n",
            "Epoch 73: loss improved from 0.90554 to 0.90322, saving model to weights-improvement-73-0.9032.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7346 - loss: 0.8807\n",
            "Epoch 74/100\n",
            "\u001b[1m411/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7377 - loss: 0.8826\n",
            "Epoch 74: loss did not improve from 0.90322\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.7377 - loss: 0.8827\n",
            "Epoch 75/100\n",
            "\u001b[1m411/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7408 - loss: 0.8713\n",
            "Epoch 75: loss improved from 0.90322 to 0.89726, saving model to weights-improvement-75-0.8973.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.7407 - loss: 0.8715\n",
            "Epoch 76/100\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7379 - loss: 0.8818\n",
            "Epoch 76: loss improved from 0.89726 to 0.88742, saving model to weights-improvement-76-0.8874.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.7379 - loss: 0.8818\n",
            "Epoch 77/100\n",
            "\u001b[1m411/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7481 - loss: 0.8596\n",
            "Epoch 77: loss improved from 0.88742 to 0.88587, saving model to weights-improvement-77-0.8859.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.7481 - loss: 0.8598\n",
            "Epoch 78/100\n",
            "\u001b[1m409/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7324 - loss: 0.8889\n",
            "Epoch 78: loss did not improve from 0.88587\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.7324 - loss: 0.8889\n",
            "Epoch 79/100\n",
            "\u001b[1m411/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7447 - loss: 0.8578\n",
            "Epoch 79: loss improved from 0.88587 to 0.87817, saving model to weights-improvement-79-0.8782.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7446 - loss: 0.8579\n",
            "Epoch 80/100\n",
            "\u001b[1m410/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7423 - loss: 0.8592\n",
            "Epoch 80: loss did not improve from 0.87817\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.7423 - loss: 0.8594\n",
            "Epoch 81/100\n",
            "\u001b[1m409/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7445 - loss: 0.8569\n",
            "Epoch 81: loss improved from 0.87817 to 0.87753, saving model to weights-improvement-81-0.8775.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.7445 - loss: 0.8571\n",
            "Epoch 82/100\n",
            "\u001b[1m409/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7455 - loss: 0.8531\n",
            "Epoch 82: loss improved from 0.87753 to 0.86897, saving model to weights-improvement-82-0.8690.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.7454 - loss: 0.8533\n",
            "Epoch 83/100\n",
            "\u001b[1m409/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7471 - loss: 0.8521\n",
            "Epoch 83: loss did not improve from 0.86897\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7471 - loss: 0.8523\n",
            "Epoch 84/100\n",
            "\u001b[1m409/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7478 - loss: 0.8421\n",
            "Epoch 84: loss improved from 0.86897 to 0.86428, saving model to weights-improvement-84-0.8643.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7478 - loss: 0.8423\n",
            "Epoch 85/100\n",
            "\u001b[1m409/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7456 - loss: 0.8470\n",
            "Epoch 85: loss improved from 0.86428 to 0.86284, saving model to weights-improvement-85-0.8628.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.7456 - loss: 0.8471\n",
            "Epoch 86/100\n",
            "\u001b[1m410/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7456 - loss: 0.8582\n",
            "Epoch 86: loss did not improve from 0.86284\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7456 - loss: 0.8583\n",
            "Epoch 87/100\n",
            "\u001b[1m409/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7397 - loss: 0.8836\n",
            "Epoch 87: loss did not improve from 0.86284\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.7396 - loss: 0.8836\n",
            "Epoch 88/100\n",
            "\u001b[1m410/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7509 - loss: 0.8211\n",
            "Epoch 88: loss improved from 0.86284 to 0.84230, saving model to weights-improvement-88-0.8423.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.7509 - loss: 0.8213\n",
            "Epoch 89/100\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7564 - loss: 0.8211\n",
            "Epoch 89: loss did not improve from 0.84230\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.7564 - loss: 0.8211\n",
            "Epoch 90/100\n",
            "\u001b[1m409/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7534 - loss: 0.8225\n",
            "Epoch 90: loss improved from 0.84230 to 0.84047, saving model to weights-improvement-90-0.8405.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.7534 - loss: 0.8227\n",
            "Epoch 91/100\n",
            "\u001b[1m411/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7470 - loss: 0.8265\n",
            "Epoch 91: loss did not improve from 0.84047\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.7470 - loss: 0.8266\n",
            "Epoch 92/100\n",
            "\u001b[1m411/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7549 - loss: 0.8141\n",
            "Epoch 92: loss improved from 0.84047 to 0.83891, saving model to weights-improvement-92-0.8389.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.7548 - loss: 0.8142\n",
            "Epoch 93/100\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7541 - loss: 0.8103\n",
            "Epoch 93: loss improved from 0.83891 to 0.82578, saving model to weights-improvement-93-0.8258.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7541 - loss: 0.8104\n",
            "Epoch 94/100\n",
            "\u001b[1m409/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7626 - loss: 0.7960\n",
            "Epoch 94: loss did not improve from 0.82578\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.7625 - loss: 0.7963\n",
            "Epoch 95/100\n",
            "\u001b[1m410/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7595 - loss: 0.8056\n",
            "Epoch 95: loss improved from 0.82578 to 0.82359, saving model to weights-improvement-95-0.8236.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.7594 - loss: 0.8057\n",
            "Epoch 96/100\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7482 - loss: 0.8246\n",
            "Epoch 96: loss did not improve from 0.82359\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.7482 - loss: 0.8246\n",
            "Epoch 97/100\n",
            "\u001b[1m411/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7514 - loss: 0.8194\n",
            "Epoch 97: loss did not improve from 0.82359\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.7514 - loss: 0.8195\n",
            "Epoch 98/100\n",
            "\u001b[1m409/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7627 - loss: 0.7980\n",
            "Epoch 98: loss improved from 0.82359 to 0.81456, saving model to weights-improvement-98-0.8146.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.7626 - loss: 0.7981\n",
            "Epoch 99/100\n",
            "\u001b[1m410/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7664 - loss: 0.7843\n",
            "Epoch 99: loss improved from 0.81456 to 0.80968, saving model to weights-improvement-99-0.8097.keras\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - accuracy: 0.7663 - loss: 0.7845\n",
            "Epoch 100/100\n",
            "\u001b[1m410/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7639 - loss: 0.7829\n",
            "Epoch 100: loss did not improve from 0.80968\n",
            "\u001b[1m412/412\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 16ms/step - accuracy: 0.7638 - loss: 0.7831\n",
            "Model telah disimpan sebagai 'trained_model.keras'\n",
            "Files found: ['weights-improvement-11-4.8795.keras', 'weights-improvement-09-5.1316.keras', 'weights-improvement-46-1.0229.keras', 'weights-improvement-52-2.2184.keras', 'weights-improvement-26-3.3715.keras', 'weights-improvement-03-5.9974.keras', 'weights-improvement-10-5.0011.keras', 'weights-improvement-44-2.4735.keras', 'weights-improvement-93-1.5213.keras', 'weights-improvement-51-2.2482.keras', 'weights-improvement-11-1.2377.keras', 'weights-improvement-27-3.2999.keras', 'weights-improvement-86-1.5894.keras', 'weights-improvement-25-3.4429.keras', 'weights-improvement-64-1.9330.keras', 'weights-improvement-82-1.6560.keras', 'weights-improvement-57-2.1126.keras', 'weights-improvement-12-4.7476.keras', 'weights-improvement-45-2.4393.keras', 'weights-improvement-76-0.8874.keras', 'weights-improvement-44-1.0338.keras', 'weights-improvement-38-1.0646.keras', 'weights-improvement-33-2.9460.keras', 'weights-improvement-15-1.2120.keras', 'weights-improvement-24-1.1431.keras', 'weights-improvement-04-5.8480.keras', 'weights-improvement-10-1.2521.keras', 'weights-improvement-23-1.1580.keras', 'weights-improvement-42-1.0458.keras', 'weights-improvement-13-4.6229.keras', 'weights-improvement-21-1.1847.keras', 'weights-improvement-52-0.9906.keras', 'weights-improvement-43-2.5099.keras', 'weights-improvement-79-1.7047.keras', 'weights-improvement-90-1.5528.keras', 'weights-improvement-98-0.8146.keras', 'weights-improvement-30-1.1076.keras', 'weights-improvement-03-1.2882.keras', 'weights-improvement-29-1.1207.keras', 'weights-improvement-41-2.5777.keras', 'weights-improvement-60-2.0069.keras', 'weights-improvement-16-4.3473.keras', 'weights-improvement-32-3.0046.keras', 'weights-improvement-96-1.4790.keras', 'weights-improvement-28-3.2353.keras', 'weights-improvement-57-0.9710.keras', 'weights-improvement-87-1.5842.keras', 'weights-improvement-78-1.7145.keras', 'weights-improvement-29-3.1669.keras', 'weights-improvement-50-1.0088.keras', 'weights-improvement-19-1.1906.keras', 'weights-improvement-21-3.7773.keras', 'weights-improvement-75-1.7619.keras', 'weights-improvement-22-3.6907.keras', 'weights-improvement-97-1.4679.keras', 'weights-improvement-71-1.8247.keras', 'weights-improvement-06-5.5634.keras', 'weights-improvement-72-1.8070.keras', 'weights-improvement-59-2.0248.keras', 'weights-improvement-02-6.1594.keras', 'weights-improvement-77-0.8859.keras', 'weights-improvement-39-2.6659.keras', 'weights-improvement-95-1.4895.keras', 'weights-improvement-50-2.2804.keras', 'weights-improvement-54-0.9902.keras', 'weights-improvement-62-1.9663.keras', 'weights-improvement-04-1.2791.keras', 'weights-improvement-23-3.6038.keras', 'weights-improvement-85-1.6140.keras', 'weights-improvement-34-1.0721.keras', 'weights-improvement-90-0.8405.keras', 'weights-improvement-88-1.5812.keras', 'weights-improvement-05-1.2730.keras', 'weights-improvement-17-4.1742.keras', 'weights-improvement-02-1.2997.keras', 'weights-improvement-65-1.9144.keras', 'trained_model.keras', 'weights-improvement-61-1.9856.keras', 'weights-improvement-55-0.9829.keras', 'weights-improvement-38-2.7040.keras', 'weights-improvement-88-0.8423.keras', 'weights-improvement-82-0.8690.keras', 'weights-improvement-26-1.1392.keras', 'weights-improvement-95-0.8236.keras', 'weights-improvement-01-6.4564.keras', 'weights-improvement-70-0.9055.keras', 'weights-improvement-62-0.9483.keras', 'weights-improvement-14-4.5105.keras', 'weights-improvement-31-3.0502.keras', 'weights-improvement-63-1.9484.keras', 'weights-improvement-15-4.3860.keras', 'weights-improvement-35-2.8624.keras', 'weights-improvement-93-0.8258.keras', 'weights-improvement-30-3.1100.keras', 'weights-improvement-59-0.9620.keras', 'weights-improvement-70-1.8456.keras', 'weights-improvement-07-5.4104.keras', 'weights-improvement-75-0.8973.keras', 'weights-improvement-92-1.5237.keras', 'weights-improvement-19-3.9740.keras', 'weights-improvement-58-2.0735.keras', 'weights-improvement-20-1.1906.keras', 'weights-improvement-65-0.9376.keras', 'weights-improvement-54-2.1722.keras', 'weights-improvement-45-1.0313.keras', 'weights-improvement-84-1.6223.keras', 'weights-improvement-79-0.8782.keras', 'weights-improvement-85-0.8628.keras', 'weights-improvement-76-1.7352.keras', 'weights-improvement-91-1.5419.keras', 'weights-improvement-49-2.3060.keras', 'weights-improvement-13-1.2238.keras', 'weights-improvement-68-0.9263.keras', 'weights-improvement-92-0.8389.keras', 'weights-improvement-73-1.8020.keras', 'weights-improvement-36-2.7916.keras', 'weights-improvement-41-1.0539.keras', 'weights-improvement-67-1.8807.keras', 'weights-improvement-81-0.8775.keras', 'weights-improvement-08-1.2651.keras', 'weights-improvement-61-0.9579.keras', 'weights-improvement-63-0.9384.keras', 'weights-improvement-74-1.7654.keras', 'weights-improvement-24-3.5324.keras', 'weights-improvement-05-5.7063.keras', 'weights-improvement-32-1.0928.keras', 'weights-improvement-99-1.4537.keras', 'weights-improvement-33-1.0891.keras', 'weights-improvement-01-1.3358.keras', 'weights-improvement-73-0.9032.keras', 'weights-improvement-68-1.8749.keras', 'weights-improvement-42-2.5450.keras', 'weights-improvement-99-0.8097.keras', 'weights-improvement-08-5.2651.keras', 'weights-improvement-47-1.0216.keras', 'weights-improvement-22-1.1676.keras', 'weights-improvement-47-2.3661.keras', 'weights-improvement-09-1.2635.keras', 'weights-improvement-17-1.2116.keras', 'weights-improvement-66-1.8808.keras', 'weights-improvement-89-1.5661.keras', 'weights-improvement-18-4.0729.keras', 'weights-improvement-39-1.0643.keras', 'weights-improvement-55-2.1351.keras', 'weights-improvement-69-1.8597.keras', 'weights-improvement-43-1.0404.keras', 'weights-improvement-53-2.2054.keras', 'weights-improvement-48-2.3342.keras', 'weights-improvement-37-2.7436.keras', 'weights-improvement-40-2.6214.keras', 'weights-improvement-80-1.6775.keras', 'weights-improvement-94-1.5046.keras', 'weights-improvement-20-3.8708.keras', 'weights-improvement-36-1.0690.keras', 'weights-improvement-18-1.1946.keras', 'weights-improvement-100-1.4337.keras', 'weights-improvement-83-1.6409.keras', 'weights-improvement-31-1.0991.keras', 'weights-improvement-34-2.8968.keras', 'weights-improvement-84-0.8643.keras', 'weights-improvement-66-0.9351.keras', 'weights-improvement-46-2.4080.keras', 'weights-improvement-67-0.9296.keras']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "epochs = 100  # Increased epochs\n",
        "batch_size = 256  # Experiment with different batch sizes\n",
        "model.fit(X, y, epochs=epochs, batch_size=batch_size, callbacks=callbacks_list)\n",
        "\n",
        "# Menyimpan model yang telah dilatih\n",
        "model.save(\"trained_model.keras\")\n",
        "print(\"Model telah disimpan sebagai 'trained_model.keras'\")\n",
        "\n",
        "# Menampilkan file .keras di direktori kerja\n",
        "files = [f for f in os.listdir() if f.endswith('.keras')]\n",
        "print(\"Files found:\", files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9r_fed-hvwX",
        "outputId": "4f8671fe-e058-4861-adc7-7ab267480a65"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m102/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7679 - loss: 0.7676\n",
            "Epoch 1: loss improved from 0.80968 to 0.75885, saving model to weights-improvement-01-0.7588.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.7680 - loss: 0.7674\n",
            "Epoch 2/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7865 - loss: 0.7154\n",
            "Epoch 2: loss improved from 0.75885 to 0.72174, saving model to weights-improvement-02-0.7217.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.7864 - loss: 0.7155\n",
            "Epoch 3/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7884 - loss: 0.6994\n",
            "Epoch 3: loss improved from 0.72174 to 0.70189, saving model to weights-improvement-03-0.7019.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.7884 - loss: 0.6995\n",
            "Epoch 4/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7940 - loss: 0.6796\n",
            "Epoch 4: loss improved from 0.70189 to 0.68778, saving model to weights-improvement-04-0.6878.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.7940 - loss: 0.6797\n",
            "Epoch 5/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7908 - loss: 0.6975\n",
            "Epoch 5: loss did not improve from 0.68778\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.7908 - loss: 0.6974\n",
            "Epoch 6/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7951 - loss: 0.6809\n",
            "Epoch 6: loss improved from 0.68778 to 0.68065, saving model to weights-improvement-06-0.6807.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.7951 - loss: 0.6809\n",
            "Epoch 7/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7974 - loss: 0.6649\n",
            "Epoch 7: loss improved from 0.68065 to 0.67429, saving model to weights-improvement-07-0.6743.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.7973 - loss: 0.6650\n",
            "Epoch 8/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8057 - loss: 0.6522\n",
            "Epoch 8: loss improved from 0.67429 to 0.66083, saving model to weights-improvement-08-0.6608.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 37ms/step - accuracy: 0.8056 - loss: 0.6523\n",
            "Epoch 9/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8009 - loss: 0.6558\n",
            "Epoch 9: loss did not improve from 0.66083\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.8008 - loss: 0.6559\n",
            "Epoch 10/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8012 - loss: 0.6650\n",
            "Epoch 10: loss did not improve from 0.66083\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.8012 - loss: 0.6650\n",
            "Epoch 11/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8068 - loss: 0.6482\n",
            "Epoch 11: loss improved from 0.66083 to 0.65584, saving model to weights-improvement-11-0.6558.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 0.8067 - loss: 0.6483\n",
            "Epoch 12/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8049 - loss: 0.6500\n",
            "Epoch 12: loss improved from 0.65584 to 0.65253, saving model to weights-improvement-12-0.6525.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8049 - loss: 0.6500\n",
            "Epoch 13/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8051 - loss: 0.6501\n",
            "Epoch 13: loss did not improve from 0.65253\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.8051 - loss: 0.6501\n",
            "Epoch 14/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8094 - loss: 0.6341\n",
            "Epoch 14: loss improved from 0.65253 to 0.64277, saving model to weights-improvement-14-0.6428.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 0.8093 - loss: 0.6342\n",
            "Epoch 15/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7996 - loss: 0.6573\n",
            "Epoch 15: loss did not improve from 0.64277\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.7996 - loss: 0.6573\n",
            "Epoch 16/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8091 - loss: 0.6385\n",
            "Epoch 16: loss did not improve from 0.64277\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.8090 - loss: 0.6386\n",
            "Epoch 17/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8072 - loss: 0.6369\n",
            "Epoch 17: loss did not improve from 0.64277\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.8072 - loss: 0.6370\n",
            "Epoch 18/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8021 - loss: 0.6572\n",
            "Epoch 18: loss did not improve from 0.64277\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.8021 - loss: 0.6571\n",
            "Epoch 19/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8079 - loss: 0.6310\n",
            "Epoch 19: loss improved from 0.64277 to 0.63740, saving model to weights-improvement-19-0.6374.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.8078 - loss: 0.6310\n",
            "Epoch 20/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8048 - loss: 0.6415\n",
            "Epoch 20: loss did not improve from 0.63740\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.8048 - loss: 0.6416\n",
            "Epoch 21/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8066 - loss: 0.6353\n",
            "Epoch 21: loss improved from 0.63740 to 0.63733, saving model to weights-improvement-21-0.6373.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.8066 - loss: 0.6353\n",
            "Epoch 22/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8148 - loss: 0.6201\n",
            "Epoch 22: loss did not improve from 0.63733\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.8147 - loss: 0.6203\n",
            "Epoch 23/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8086 - loss: 0.6345\n",
            "Epoch 23: loss did not improve from 0.63733\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8085 - loss: 0.6346\n",
            "Epoch 24/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8047 - loss: 0.6460\n",
            "Epoch 24: loss did not improve from 0.63733\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.8047 - loss: 0.6460\n",
            "Epoch 25/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8087 - loss: 0.6260\n",
            "Epoch 25: loss did not improve from 0.63733\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.8087 - loss: 0.6261\n",
            "Epoch 26/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8127 - loss: 0.6181\n",
            "Epoch 26: loss improved from 0.63733 to 0.63277, saving model to weights-improvement-26-0.6328.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.8127 - loss: 0.6183\n",
            "Epoch 27/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8091 - loss: 0.6315\n",
            "Epoch 27: loss did not improve from 0.63277\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.8090 - loss: 0.6317\n",
            "Epoch 28/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8111 - loss: 0.6283\n",
            "Epoch 28: loss improved from 0.63277 to 0.62921, saving model to weights-improvement-28-0.6292.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 0.8111 - loss: 0.6283\n",
            "Epoch 29/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8035 - loss: 0.6392\n",
            "Epoch 29: loss did not improve from 0.62921\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.8035 - loss: 0.6392\n",
            "Epoch 30/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8100 - loss: 0.6138\n",
            "Epoch 30: loss improved from 0.62921 to 0.62817, saving model to weights-improvement-30-0.6282.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8100 - loss: 0.6139\n",
            "Epoch 31/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8172 - loss: 0.6131\n",
            "Epoch 31: loss improved from 0.62817 to 0.62694, saving model to weights-improvement-31-0.6269.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8172 - loss: 0.6133\n",
            "Epoch 32/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8089 - loss: 0.6313\n",
            "Epoch 32: loss did not improve from 0.62694\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.8089 - loss: 0.6313\n",
            "Epoch 33/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8107 - loss: 0.6255\n",
            "Epoch 33: loss did not improve from 0.62694\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.8107 - loss: 0.6255\n",
            "Epoch 34/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8141 - loss: 0.6151\n",
            "Epoch 34: loss improved from 0.62694 to 0.61918, saving model to weights-improvement-34-0.6192.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.8141 - loss: 0.6151\n",
            "Epoch 35/100\n",
            "\u001b[1m102/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8096 - loss: 0.6169\n",
            "Epoch 35: loss did not improve from 0.61918\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.8095 - loss: 0.6170\n",
            "Epoch 36/100\n",
            "\u001b[1m102/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8170 - loss: 0.6098\n",
            "Epoch 36: loss improved from 0.61918 to 0.61856, saving model to weights-improvement-36-0.6186.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.8169 - loss: 0.6099\n",
            "Epoch 37/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8123 - loss: 0.6163\n",
            "Epoch 37: loss improved from 0.61856 to 0.61846, saving model to weights-improvement-37-0.6185.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.8123 - loss: 0.6163\n",
            "Epoch 38/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8131 - loss: 0.6199\n",
            "Epoch 38: loss did not improve from 0.61846\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 46ms/step - accuracy: 0.8131 - loss: 0.6199\n",
            "Epoch 39/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8160 - loss: 0.6095\n",
            "Epoch 39: loss did not improve from 0.61846\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.8159 - loss: 0.6096\n",
            "Epoch 40/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8129 - loss: 0.6166\n",
            "Epoch 40: loss did not improve from 0.61846\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.8129 - loss: 0.6167\n",
            "Epoch 41/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8139 - loss: 0.6129\n",
            "Epoch 41: loss did not improve from 0.61846\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.8139 - loss: 0.6130\n",
            "Epoch 42/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8180 - loss: 0.6048\n",
            "Epoch 42: loss improved from 0.61846 to 0.60774, saving model to weights-improvement-42-0.6077.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8180 - loss: 0.6048\n",
            "Epoch 43/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8157 - loss: 0.6046\n",
            "Epoch 43: loss did not improve from 0.60774\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.8157 - loss: 0.6047\n",
            "Epoch 44/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8134 - loss: 0.6096\n",
            "Epoch 44: loss did not improve from 0.60774\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.8133 - loss: 0.6097\n",
            "Epoch 45/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8140 - loss: 0.6153\n",
            "Epoch 45: loss did not improve from 0.60774\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.8140 - loss: 0.6153\n",
            "Epoch 46/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8149 - loss: 0.6162\n",
            "Epoch 46: loss did not improve from 0.60774\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.8148 - loss: 0.6161\n",
            "Epoch 47/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8172 - loss: 0.6110\n",
            "Epoch 47: loss did not improve from 0.60774\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.8172 - loss: 0.6111\n",
            "Epoch 48/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8183 - loss: 0.5955\n",
            "Epoch 48: loss improved from 0.60774 to 0.59938, saving model to weights-improvement-48-0.5994.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.8183 - loss: 0.5955\n",
            "Epoch 49/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8168 - loss: 0.5932\n",
            "Epoch 49: loss did not improve from 0.59938\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.8168 - loss: 0.5933\n",
            "Epoch 50/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8138 - loss: 0.6022\n",
            "Epoch 50: loss did not improve from 0.59938\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 0.8138 - loss: 0.6023\n",
            "Epoch 51/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8232 - loss: 0.5847\n",
            "Epoch 51: loss did not improve from 0.59938\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.8231 - loss: 0.5849\n",
            "Epoch 52/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8200 - loss: 0.5913\n",
            "Epoch 52: loss did not improve from 0.59938\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.8199 - loss: 0.5914\n",
            "Epoch 53/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8172 - loss: 0.5973\n",
            "Epoch 53: loss did not improve from 0.59938\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.8172 - loss: 0.5974\n",
            "Epoch 54/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8152 - loss: 0.6042\n",
            "Epoch 54: loss did not improve from 0.59938\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.8152 - loss: 0.6042\n",
            "Epoch 55/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8200 - loss: 0.5904\n",
            "Epoch 55: loss did not improve from 0.59938\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.8199 - loss: 0.5906\n",
            "Epoch 56/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8226 - loss: 0.5804\n",
            "Epoch 56: loss improved from 0.59938 to 0.59255, saving model to weights-improvement-56-0.5925.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.8226 - loss: 0.5805\n",
            "Epoch 57/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8214 - loss: 0.5787\n",
            "Epoch 57: loss improved from 0.59255 to 0.58734, saving model to weights-improvement-57-0.5873.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.8214 - loss: 0.5788\n",
            "Epoch 58/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8227 - loss: 0.5860\n",
            "Epoch 58: loss did not improve from 0.58734\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.8227 - loss: 0.5861\n",
            "Epoch 59/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8204 - loss: 0.5939\n",
            "Epoch 59: loss did not improve from 0.58734\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.8204 - loss: 0.5940\n",
            "Epoch 60/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8192 - loss: 0.6018\n",
            "Epoch 60: loss did not improve from 0.58734\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.8192 - loss: 0.6017\n",
            "Epoch 61/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8240 - loss: 0.5783\n",
            "Epoch 61: loss did not improve from 0.58734\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.8239 - loss: 0.5785\n",
            "Epoch 62/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8228 - loss: 0.5818\n",
            "Epoch 62: loss improved from 0.58734 to 0.58342, saving model to weights-improvement-62-0.5834.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 0.8228 - loss: 0.5818\n",
            "Epoch 63/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8243 - loss: 0.5807\n",
            "Epoch 63: loss did not improve from 0.58342\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.8242 - loss: 0.5807\n",
            "Epoch 64/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8248 - loss: 0.5806\n",
            "Epoch 64: loss did not improve from 0.58342\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.8248 - loss: 0.5807\n",
            "Epoch 65/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8275 - loss: 0.5734\n",
            "Epoch 65: loss improved from 0.58342 to 0.58269, saving model to weights-improvement-65-0.5827.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 0.8274 - loss: 0.5734\n",
            "Epoch 66/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8269 - loss: 0.5670\n",
            "Epoch 66: loss improved from 0.58269 to 0.57049, saving model to weights-improvement-66-0.5705.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8269 - loss: 0.5671\n",
            "Epoch 67/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8279 - loss: 0.5654\n",
            "Epoch 67: loss did not improve from 0.57049\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8278 - loss: 0.5655\n",
            "Epoch 68/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8268 - loss: 0.5617\n",
            "Epoch 68: loss did not improve from 0.57049\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8268 - loss: 0.5618\n",
            "Epoch 69/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8224 - loss: 0.5824\n",
            "Epoch 69: loss did not improve from 0.57049\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.8224 - loss: 0.5824\n",
            "Epoch 70/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8249 - loss: 0.5645\n",
            "Epoch 70: loss did not improve from 0.57049\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.8249 - loss: 0.5646\n",
            "Epoch 71/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8296 - loss: 0.5579\n",
            "Epoch 71: loss improved from 0.57049 to 0.56939, saving model to weights-improvement-71-0.5694.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 0.8296 - loss: 0.5580\n",
            "Epoch 72/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8277 - loss: 0.5712\n",
            "Epoch 72: loss did not improve from 0.56939\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.8277 - loss: 0.5712\n",
            "Epoch 73/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8300 - loss: 0.5591\n",
            "Epoch 73: loss improved from 0.56939 to 0.56597, saving model to weights-improvement-73-0.5660.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8300 - loss: 0.5592\n",
            "Epoch 74/100\n",
            "\u001b[1m102/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8262 - loss: 0.5701\n",
            "Epoch 74: loss did not improve from 0.56597\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 0.8262 - loss: 0.5703\n",
            "Epoch 75/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8262 - loss: 0.5639\n",
            "Epoch 75: loss improved from 0.56597 to 0.56397, saving model to weights-improvement-75-0.5640.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.8262 - loss: 0.5639\n",
            "Epoch 76/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8270 - loss: 0.5689\n",
            "Epoch 76: loss did not improve from 0.56397\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.8270 - loss: 0.5690\n",
            "Epoch 77/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8341 - loss: 0.5441\n",
            "Epoch 77: loss improved from 0.56397 to 0.55564, saving model to weights-improvement-77-0.5556.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 37ms/step - accuracy: 0.8340 - loss: 0.5442\n",
            "Epoch 78/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8299 - loss: 0.5699\n",
            "Epoch 78: loss did not improve from 0.55564\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.8299 - loss: 0.5699\n",
            "Epoch 79/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8345 - loss: 0.5417\n",
            "Epoch 79: loss did not improve from 0.55564\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.8344 - loss: 0.5419\n",
            "Epoch 80/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8287 - loss: 0.5599\n",
            "Epoch 80: loss did not improve from 0.55564\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8287 - loss: 0.5600\n",
            "Epoch 81/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8282 - loss: 0.5604\n",
            "Epoch 81: loss did not improve from 0.55564\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8282 - loss: 0.5605\n",
            "Epoch 82/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8278 - loss: 0.5548\n",
            "Epoch 82: loss did not improve from 0.55564\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.8278 - loss: 0.5548\n",
            "Epoch 83/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8303 - loss: 0.5520\n",
            "Epoch 83: loss improved from 0.55564 to 0.55543, saving model to weights-improvement-83-0.5554.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8303 - loss: 0.5520\n",
            "Epoch 84/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8272 - loss: 0.5620\n",
            "Epoch 84: loss did not improve from 0.55543\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.8272 - loss: 0.5621\n",
            "Epoch 85/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8315 - loss: 0.5512\n",
            "Epoch 85: loss did not improve from 0.55543\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.8314 - loss: 0.5513\n",
            "Epoch 86/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8201 - loss: 0.5893\n",
            "Epoch 86: loss did not improve from 0.55543\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.8200 - loss: 0.5895\n",
            "Epoch 87/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8260 - loss: 0.5707\n",
            "Epoch 87: loss did not improve from 0.55543\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8259 - loss: 0.5708\n",
            "Epoch 88/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8296 - loss: 0.5670\n",
            "Epoch 88: loss did not improve from 0.55543\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.8296 - loss: 0.5671\n",
            "Epoch 89/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8222 - loss: 0.6071\n",
            "Epoch 89: loss did not improve from 0.55543\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8222 - loss: 0.6070\n",
            "Epoch 90/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8297 - loss: 0.5626\n",
            "Epoch 90: loss did not improve from 0.55543\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8297 - loss: 0.5626\n",
            "Epoch 91/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8088 - loss: 0.6206\n",
            "Epoch 91: loss did not improve from 0.55543\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 36ms/step - accuracy: 0.8087 - loss: 0.6209\n",
            "Epoch 92/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8128 - loss: 0.6064\n",
            "Epoch 92: loss did not improve from 0.55543\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 34ms/step - accuracy: 0.8127 - loss: 0.6064\n",
            "Epoch 93/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8284 - loss: 0.5568\n",
            "Epoch 93: loss did not improve from 0.55543\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.8284 - loss: 0.5569\n",
            "Epoch 94/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8261 - loss: 0.5660\n",
            "Epoch 94: loss did not improve from 0.55543\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.8261 - loss: 0.5661\n",
            "Epoch 95/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8322 - loss: 0.5446\n",
            "Epoch 95: loss improved from 0.55543 to 0.54849, saving model to weights-improvement-95-0.5485.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8322 - loss: 0.5447\n",
            "Epoch 96/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8283 - loss: 0.5576\n",
            "Epoch 96: loss did not improve from 0.54849\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.8283 - loss: 0.5576\n",
            "Epoch 97/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8293 - loss: 0.5459\n",
            "Epoch 97: loss did not improve from 0.54849\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8293 - loss: 0.5461\n",
            "Epoch 98/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8372 - loss: 0.5324\n",
            "Epoch 98: loss improved from 0.54849 to 0.54034, saving model to weights-improvement-98-0.5403.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.8372 - loss: 0.5325\n",
            "Epoch 99/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8347 - loss: 0.5371\n",
            "Epoch 99: loss improved from 0.54034 to 0.53829, saving model to weights-improvement-99-0.5383.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 35ms/step - accuracy: 0.8347 - loss: 0.5371\n",
            "Epoch 100/100\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8380 - loss: 0.5288\n",
            "Epoch 100: loss improved from 0.53829 to 0.53264, saving model to weights-improvement-100-0.5326.keras\n",
            "\u001b[1m103/103\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 36ms/step - accuracy: 0.8380 - loss: 0.5289\n",
            "Model telah disimpan sebagai 'trained_model.keras'\n",
            "Files found: ['weights-improvement-11-4.8795.keras', 'weights-improvement-09-5.1316.keras', 'weights-improvement-46-1.0229.keras', 'weights-improvement-11-0.6558.keras', 'weights-improvement-14-0.6428.keras', 'weights-improvement-52-2.2184.keras', 'weights-improvement-26-3.3715.keras', 'weights-improvement-03-5.9974.keras', 'weights-improvement-10-5.0011.keras', 'weights-improvement-44-2.4735.keras', 'weights-improvement-93-1.5213.keras', 'weights-improvement-06-0.6807.keras', 'weights-improvement-51-2.2482.keras', 'weights-improvement-11-1.2377.keras', 'weights-improvement-27-3.2999.keras', 'weights-improvement-86-1.5894.keras', 'weights-improvement-25-3.4429.keras', 'weights-improvement-64-1.9330.keras', 'weights-improvement-82-1.6560.keras', 'weights-improvement-95-0.5485.keras', 'weights-improvement-57-2.1126.keras', 'weights-improvement-12-4.7476.keras', 'weights-improvement-45-2.4393.keras', 'weights-improvement-76-0.8874.keras', 'weights-improvement-44-1.0338.keras', 'weights-improvement-38-1.0646.keras', 'weights-improvement-33-2.9460.keras', 'weights-improvement-15-1.2120.keras', 'weights-improvement-24-1.1431.keras', 'weights-improvement-04-5.8480.keras', 'weights-improvement-10-1.2521.keras', 'weights-improvement-23-1.1580.keras', 'weights-improvement-42-1.0458.keras', 'weights-improvement-13-4.6229.keras', 'weights-improvement-21-1.1847.keras', 'weights-improvement-52-0.9906.keras', 'weights-improvement-04-0.6878.keras', 'weights-improvement-43-2.5099.keras', 'weights-improvement-79-1.7047.keras', 'weights-improvement-90-1.5528.keras', 'weights-improvement-98-0.8146.keras', 'weights-improvement-30-1.1076.keras', 'weights-improvement-03-1.2882.keras', 'weights-improvement-29-1.1207.keras', 'weights-improvement-41-2.5777.keras', 'weights-improvement-03-0.7019.keras', 'weights-improvement-60-2.0069.keras', 'weights-improvement-16-4.3473.keras', 'weights-improvement-32-3.0046.keras', 'weights-improvement-01-0.7588.keras', 'weights-improvement-96-1.4790.keras', 'weights-improvement-28-3.2353.keras', 'weights-improvement-57-0.9710.keras', 'weights-improvement-87-1.5842.keras', 'weights-improvement-78-1.7145.keras', 'weights-improvement-29-3.1669.keras', 'weights-improvement-50-1.0088.keras', 'weights-improvement-19-1.1906.keras', 'weights-improvement-31-0.6269.keras', 'weights-improvement-21-3.7773.keras', 'weights-improvement-75-1.7619.keras', 'weights-improvement-22-3.6907.keras', 'weights-improvement-97-1.4679.keras', 'weights-improvement-71-1.8247.keras', 'weights-improvement-06-5.5634.keras', 'weights-improvement-72-1.8070.keras', 'weights-improvement-59-2.0248.keras', 'weights-improvement-02-6.1594.keras', 'weights-improvement-71-0.5694.keras', 'weights-improvement-77-0.8859.keras', 'weights-improvement-98-0.5403.keras', 'weights-improvement-39-2.6659.keras', 'weights-improvement-36-0.6186.keras', 'weights-improvement-95-1.4895.keras', 'weights-improvement-50-2.2804.keras', 'weights-improvement-48-0.5994.keras', 'weights-improvement-54-0.9902.keras', 'weights-improvement-62-1.9663.keras', 'weights-improvement-04-1.2791.keras', 'weights-improvement-23-3.6038.keras', 'weights-improvement-85-1.6140.keras', 'weights-improvement-34-1.0721.keras', 'weights-improvement-08-0.6608.keras', 'weights-improvement-90-0.8405.keras', 'weights-improvement-88-1.5812.keras', 'weights-improvement-65-0.5827.keras', 'weights-improvement-05-1.2730.keras', 'weights-improvement-17-4.1742.keras', 'weights-improvement-75-0.5640.keras', 'weights-improvement-02-1.2997.keras', 'weights-improvement-65-1.9144.keras', 'trained_model.keras', 'weights-improvement-61-1.9856.keras', 'weights-improvement-55-0.9829.keras', 'weights-improvement-38-2.7040.keras', 'weights-improvement-88-0.8423.keras', 'weights-improvement-82-0.8690.keras', 'weights-improvement-26-1.1392.keras', 'weights-improvement-95-0.8236.keras', 'weights-improvement-01-6.4564.keras', 'weights-improvement-70-0.9055.keras', 'weights-improvement-62-0.9483.keras', 'weights-improvement-14-4.5105.keras', 'weights-improvement-31-3.0502.keras', 'weights-improvement-63-1.9484.keras', 'weights-improvement-15-4.3860.keras', 'weights-improvement-35-2.8624.keras', 'weights-improvement-93-0.8258.keras', 'weights-improvement-30-3.1100.keras', 'weights-improvement-62-0.5834.keras', 'weights-improvement-59-0.9620.keras', 'weights-improvement-70-1.8456.keras', 'weights-improvement-07-5.4104.keras', 'weights-improvement-75-0.8973.keras', 'weights-improvement-73-0.5660.keras', 'weights-improvement-66-0.5705.keras', 'weights-improvement-92-1.5237.keras', 'weights-improvement-19-3.9740.keras', 'weights-improvement-58-2.0735.keras', 'weights-improvement-20-1.1906.keras', 'weights-improvement-65-0.9376.keras', 'weights-improvement-54-2.1722.keras', 'weights-improvement-45-1.0313.keras', 'weights-improvement-84-1.6223.keras', 'weights-improvement-79-0.8782.keras', 'weights-improvement-85-0.8628.keras', 'weights-improvement-21-0.6373.keras', 'weights-improvement-57-0.5873.keras', 'weights-improvement-76-1.7352.keras', 'weights-improvement-91-1.5419.keras', 'weights-improvement-49-2.3060.keras', 'weights-improvement-13-1.2238.keras', 'weights-improvement-19-0.6374.keras', 'weights-improvement-34-0.6192.keras', 'weights-improvement-68-0.9263.keras', 'weights-improvement-77-0.5556.keras', 'weights-improvement-92-0.8389.keras', 'weights-improvement-56-0.5925.keras', 'weights-improvement-73-1.8020.keras', 'weights-improvement-36-2.7916.keras', 'weights-improvement-41-1.0539.keras', 'weights-improvement-67-1.8807.keras', 'weights-improvement-81-0.8775.keras', 'weights-improvement-37-0.6185.keras', 'weights-improvement-08-1.2651.keras', 'weights-improvement-100-0.5326.keras', 'weights-improvement-61-0.9579.keras', 'weights-improvement-63-0.9384.keras', 'weights-improvement-74-1.7654.keras', 'weights-improvement-24-3.5324.keras', 'weights-improvement-05-5.7063.keras', 'weights-improvement-32-1.0928.keras', 'weights-improvement-02-0.7217.keras', 'weights-improvement-99-1.4537.keras', 'weights-improvement-33-1.0891.keras', 'weights-improvement-42-0.6077.keras', 'weights-improvement-01-1.3358.keras', 'weights-improvement-26-0.6328.keras', 'weights-improvement-73-0.9032.keras', 'weights-improvement-68-1.8749.keras', 'weights-improvement-42-2.5450.keras', 'weights-improvement-99-0.8097.keras', 'weights-improvement-08-5.2651.keras', 'weights-improvement-47-1.0216.keras', 'weights-improvement-22-1.1676.keras', 'weights-improvement-30-0.6282.keras', 'weights-improvement-47-2.3661.keras', 'weights-improvement-09-1.2635.keras', 'weights-improvement-17-1.2116.keras', 'weights-improvement-66-1.8808.keras', 'weights-improvement-89-1.5661.keras', 'weights-improvement-18-4.0729.keras', 'weights-improvement-39-1.0643.keras', 'weights-improvement-55-2.1351.keras', 'weights-improvement-69-1.8597.keras', 'weights-improvement-43-1.0404.keras', 'weights-improvement-07-0.6743.keras', 'weights-improvement-53-2.2054.keras', 'weights-improvement-48-2.3342.keras', 'weights-improvement-37-2.7436.keras', 'weights-improvement-40-2.6214.keras', 'weights-improvement-80-1.6775.keras', 'weights-improvement-94-1.5046.keras', 'weights-improvement-20-3.8708.keras', 'weights-improvement-36-1.0690.keras', 'weights-improvement-18-1.1946.keras', 'weights-improvement-28-0.6292.keras', 'weights-improvement-100-1.4337.keras', 'weights-improvement-83-1.6409.keras', 'weights-improvement-12-0.6525.keras', 'weights-improvement-31-1.0991.keras', 'weights-improvement-34-2.8968.keras', 'weights-improvement-83-0.5554.keras', 'weights-improvement-99-0.5383.keras', 'weights-improvement-84-0.8643.keras', 'weights-improvement-66-0.9351.keras', 'weights-improvement-46-2.4080.keras', 'weights-improvement-67-0.9296.keras']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "epochs = 10  # Increased epochs\n",
        "batch_size = 3200  # Experiment with different batch sizes\n",
        "history = model.fit(X, y, epochs=epochs, batch_size=batch_size, callbacks=callbacks_list)\n",
        "\n",
        "# Menyimpan model yang telah dilatih\n",
        "model.save(\"trained_model.keras\")\n",
        "print(\"Model telah disimpan sebagai 'trained_model.keras'\")\n",
        "\n",
        "# Menampilkan file .keras di direktori kerja\n",
        "files = [f for f in os.listdir() if f.endswith('.keras')]\n",
        "print(\"Files found:\", files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLvJsNJ2rSUK",
        "outputId": "5c221f36-bf30-4687-fe27-59124567e570"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 0.9091 - loss: 0.2933\n",
            "Epoch 1: loss improved from 0.31078 to 0.30292, saving model to weights-improvement-01-0.3029.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 306ms/step - accuracy: 0.9087 - loss: 0.2943\n",
            "Epoch 2/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 0.9029 - loss: 0.3143\n",
            "Epoch 2: loss did not improve from 0.30292\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 296ms/step - accuracy: 0.9029 - loss: 0.3144\n",
            "Epoch 3/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.9015 - loss: 0.3097\n",
            "Epoch 3: loss did not improve from 0.30292\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 309ms/step - accuracy: 0.9017 - loss: 0.3093\n",
            "Epoch 4/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - accuracy: 0.9033 - loss: 0.3129\n",
            "Epoch 4: loss did not improve from 0.30292\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 298ms/step - accuracy: 0.9033 - loss: 0.3126\n",
            "Epoch 5/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.9009 - loss: 0.3113\n",
            "Epoch 5: loss did not improve from 0.30292\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 302ms/step - accuracy: 0.9010 - loss: 0.3111\n",
            "Epoch 6/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.9010 - loss: 0.3133\n",
            "Epoch 6: loss did not improve from 0.30292\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 302ms/step - accuracy: 0.9010 - loss: 0.3132\n",
            "Epoch 7/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.9013 - loss: 0.3197\n",
            "Epoch 7: loss did not improve from 0.30292\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 302ms/step - accuracy: 0.9015 - loss: 0.3193\n",
            "Epoch 8/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - accuracy: 0.9047 - loss: 0.3052\n",
            "Epoch 8: loss did not improve from 0.30292\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 305ms/step - accuracy: 0.9045 - loss: 0.3053\n",
            "Epoch 9/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.9056 - loss: 0.3012\n",
            "Epoch 9: loss improved from 0.30292 to 0.30170, saving model to weights-improvement-09-0.3017.keras\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 323ms/step - accuracy: 0.9056 - loss: 0.3012\n",
            "Epoch 10/10\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.9039 - loss: 0.3082\n",
            "Epoch 10: loss did not improve from 0.30170\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 303ms/step - accuracy: 0.9038 - loss: 0.3083\n",
            "Model telah disimpan sebagai 'trained_model.keras'\n",
            "Files found: ['weights-improvement-11-4.8795.keras', 'weights-improvement-14-0.3394.keras', 'weights-improvement-09-5.1316.keras', 'weights-improvement-46-1.0229.keras', 'weights-improvement-11-0.6558.keras', 'weights-improvement-14-0.6428.keras', 'weights-improvement-57-0.3935.keras', 'weights-improvement-20-0.4228.keras', 'weights-improvement-52-2.2184.keras', 'weights-improvement-26-3.3715.keras', 'weights-improvement-05-0.3424.keras', 'weights-improvement-03-5.9974.keras', 'weights-improvement-10-5.0011.keras', 'weights-improvement-44-2.4735.keras', 'weights-improvement-93-1.5213.keras', 'weights-improvement-93-0.3815.keras', 'weights-improvement-06-0.3189.keras', 'weights-improvement-58-0.4675.keras', 'weights-improvement-54-0.4676.keras', 'weights-improvement-06-0.6807.keras', 'weights-improvement-51-2.2482.keras', 'weights-improvement-11-1.2377.keras', 'weights-improvement-27-3.2999.keras', 'weights-improvement-86-1.5894.keras', 'weights-improvement-25-3.4429.keras', 'weights-improvement-64-1.9330.keras', 'weights-improvement-82-1.6560.keras', 'weights-improvement-88-0.4510.keras', 'weights-improvement-95-0.5485.keras', 'weights-improvement-57-2.1126.keras', 'weights-improvement-12-4.7476.keras', 'weights-improvement-45-2.4393.keras', 'weights-improvement-76-0.8874.keras', 'weights-improvement-44-1.0338.keras', 'weights-improvement-38-1.0646.keras', 'weights-improvement-09-0.3017.keras', 'weights-improvement-13-0.3398.keras', 'weights-improvement-37-0.4157.keras', 'weights-improvement-33-2.9460.keras', 'weights-improvement-15-1.2120.keras', 'weights-improvement-40-0.4855.keras', 'weights-improvement-24-1.1431.keras', 'weights-improvement-04-5.8480.keras', 'weights-improvement-10-1.2521.keras', 'weights-improvement-23-1.1580.keras', 'weights-improvement-49-0.4727.keras', 'weights-improvement-42-1.0458.keras', 'weights-improvement-13-4.6229.keras', 'weights-improvement-34-0.4196.keras', 'weights-improvement-21-1.1847.keras', 'weights-improvement-52-0.9906.keras', 'weights-improvement-04-0.6878.keras', 'weights-improvement-43-2.5099.keras', 'weights-improvement-79-1.7047.keras', 'weights-improvement-02-0.3671.keras', 'weights-improvement-90-1.5528.keras', 'weights-improvement-98-0.8146.keras', 'weights-improvement-29-0.4198.keras', 'weights-improvement-18-0.5049.keras', 'weights-improvement-30-1.1076.keras', 'weights-improvement-69-0.4629.keras', 'weights-improvement-03-1.2882.keras', 'weights-improvement-29-1.1207.keras', 'weights-improvement-15-0.4255.keras', 'weights-improvement-41-2.5777.keras', 'weights-improvement-03-0.7019.keras', 'weights-improvement-60-2.0069.keras', 'weights-improvement-08-0.5087.keras', 'weights-improvement-19-0.5025.keras', 'weights-improvement-16-4.3473.keras', 'weights-improvement-32-3.0046.keras', 'weights-improvement-01-0.7588.keras', 'weights-improvement-07-0.3411.keras', 'weights-improvement-96-1.4790.keras', 'weights-improvement-28-3.2353.keras', 'weights-improvement-57-0.9710.keras', 'weights-improvement-42-0.4083.keras', 'weights-improvement-72-0.4583.keras', 'weights-improvement-05-0.4284.keras', 'weights-improvement-87-1.5842.keras', 'weights-improvement-78-1.7145.keras', 'weights-improvement-29-3.1669.keras', 'weights-improvement-50-1.0088.keras', 'weights-improvement-19-1.1906.keras', 'weights-improvement-31-0.6269.keras', 'weights-improvement-21-3.7773.keras', 'weights-improvement-01-0.3686.keras', 'weights-improvement-75-1.7619.keras', 'weights-improvement-22-3.6907.keras', 'weights-improvement-97-1.4679.keras', 'weights-improvement-71-1.8247.keras', 'weights-improvement-06-5.5634.keras', 'weights-improvement-72-1.8070.keras', 'weights-improvement-59-2.0248.keras', 'weights-improvement-02-6.1594.keras', 'weights-improvement-71-0.5694.keras', 'weights-improvement-33-0.4863.keras', 'weights-improvement-77-0.8859.keras', 'weights-improvement-98-0.5403.keras', 'weights-improvement-39-2.6659.keras', 'weights-improvement-36-0.6186.keras', 'weights-improvement-14-0.5060.keras', 'weights-improvement-95-1.4895.keras', 'weights-improvement-50-2.2804.keras', 'weights-improvement-09-0.3285.keras', 'weights-improvement-48-0.5994.keras', 'weights-improvement-54-0.9902.keras', 'weights-improvement-62-1.9663.keras', 'weights-improvement-26-0.4979.keras', 'weights-improvement-84-0.4553.keras', 'weights-improvement-04-1.2791.keras', 'weights-improvement-23-3.6038.keras', 'weights-improvement-85-1.6140.keras', 'weights-improvement-34-1.0721.keras', 'weights-improvement-04-0.3191.keras', 'weights-improvement-08-0.6608.keras', 'weights-improvement-90-0.8405.keras', 'weights-improvement-30-0.4926.keras', 'weights-improvement-88-1.5812.keras', 'weights-improvement-45-0.4034.keras', 'weights-improvement-65-0.5827.keras', 'weights-improvement-44-0.4850.keras', 'weights-improvement-05-1.2730.keras', 'weights-improvement-17-4.1742.keras', 'weights-improvement-01-0.3029.keras', 'weights-improvement-03-0.3548.keras', 'weights-improvement-75-0.5640.keras', 'weights-improvement-02-1.2997.keras', 'weights-improvement-13-0.5075.keras', 'weights-improvement-65-1.9144.keras', 'trained_model.keras', 'weights-improvement-61-1.9856.keras', 'weights-improvement-55-0.9829.keras', 'weights-improvement-38-2.7040.keras', 'weights-improvement-88-0.8423.keras', 'weights-improvement-82-0.8690.keras', 'weights-improvement-67-0.3863.keras', 'weights-improvement-26-1.1392.keras', 'weights-improvement-95-0.8236.keras', 'weights-improvement-01-6.4564.keras', 'weights-improvement-70-0.9055.keras', 'weights-improvement-62-0.9483.keras', 'weights-improvement-14-4.5105.keras', 'weights-improvement-31-3.0502.keras', 'weights-improvement-63-1.9484.keras', 'weights-improvement-15-4.3860.keras', 'weights-improvement-35-2.8624.keras', 'weights-improvement-93-0.8258.keras', 'weights-improvement-30-3.1100.keras', 'weights-improvement-62-0.5834.keras', 'weights-improvement-59-0.9620.keras', 'weights-improvement-70-1.8456.keras', 'weights-improvement-07-5.4104.keras', 'weights-improvement-04-0.5152.keras', 'weights-improvement-75-0.8973.keras', 'weights-improvement-73-0.5660.keras', 'weights-improvement-66-0.5705.keras', 'weights-improvement-92-1.5237.keras', 'weights-improvement-19-3.9740.keras', 'weights-improvement-58-2.0735.keras', 'weights-improvement-36-0.4860.keras', 'weights-improvement-83-0.4559.keras', 'weights-improvement-20-1.1906.keras', 'weights-improvement-65-0.9376.keras', 'weights-improvement-54-2.1722.keras', 'weights-improvement-17-0.3292.keras', 'weights-improvement-45-1.0313.keras', 'weights-improvement-84-1.6223.keras', 'weights-improvement-79-0.8782.keras', 'weights-improvement-85-0.8628.keras', 'weights-improvement-21-0.6373.keras', 'weights-improvement-57-0.5873.keras', 'weights-improvement-76-1.7352.keras', 'weights-improvement-44-0.4074.keras', 'weights-improvement-91-1.5419.keras', 'weights-improvement-49-2.3060.keras', 'weights-improvement-13-1.2238.keras', 'weights-improvement-19-0.6374.keras', 'weights-improvement-34-0.6192.keras', 'weights-improvement-68-0.9263.keras', 'weights-improvement-77-0.5556.keras', 'weights-improvement-92-0.8389.keras', 'weights-improvement-56-0.5925.keras', 'weights-improvement-73-1.8020.keras', 'weights-improvement-87-0.4540.keras', 'weights-improvement-36-2.7916.keras', 'weights-improvement-41-1.0539.keras', 'weights-improvement-67-1.8807.keras', 'weights-improvement-92-0.3850.keras', 'weights-improvement-81-0.8775.keras', 'weights-improvement-07-0.3178.keras', 'weights-improvement-37-0.6185.keras', 'weights-improvement-08-1.2651.keras', 'weights-improvement-100-0.5326.keras', 'weights-improvement-01-0.3333.keras', 'weights-improvement-61-0.9579.keras', 'weights-improvement-63-0.9384.keras', 'weights-improvement-74-1.7654.keras', 'weights-improvement-24-3.5324.keras', 'weights-improvement-05-5.7063.keras', 'weights-improvement-32-1.0928.keras', 'weights-improvement-04-0.3448.keras', 'weights-improvement-39-0.4156.keras', 'weights-improvement-02-0.7217.keras', 'weights-improvement-99-1.4537.keras', 'weights-improvement-33-1.0891.keras', 'weights-improvement-42-0.6077.keras', 'weights-improvement-01-1.3358.keras', 'weights-improvement-26-0.6328.keras', 'weights-improvement-73-0.9032.keras', 'weights-improvement-68-1.8749.keras', 'weights-improvement-42-2.5450.keras', 'weights-improvement-99-0.8097.keras', 'weights-improvement-08-5.2651.keras', 'weights-improvement-47-1.0216.keras', 'weights-improvement-98-0.3749.keras', 'weights-improvement-22-1.1676.keras', 'weights-improvement-30-0.6282.keras', 'weights-improvement-100-0.4364.keras', 'weights-improvement-47-2.3661.keras', 'weights-improvement-09-1.2635.keras', 'weights-improvement-03-0.5317.keras', 'weights-improvement-10-0.3108.keras', 'weights-improvement-23-0.4980.keras', 'weights-improvement-17-1.2116.keras', 'weights-improvement-66-1.8808.keras', 'weights-improvement-02-0.3250.keras', 'weights-improvement-45-0.4767.keras', 'weights-improvement-89-1.5661.keras', 'weights-improvement-18-4.0729.keras', 'weights-improvement-39-1.0643.keras', 'weights-improvement-55-2.1351.keras', 'weights-improvement-69-1.8597.keras', 'weights-improvement-43-1.0404.keras', 'weights-improvement-07-0.6743.keras', 'weights-improvement-53-2.2054.keras', 'weights-improvement-48-2.3342.keras', 'weights-improvement-37-2.7436.keras', 'weights-improvement-40-2.6214.keras', 'weights-improvement-80-1.6775.keras', 'weights-improvement-89-0.4429.keras', 'weights-improvement-94-1.5046.keras', 'weights-improvement-20-3.8708.keras', 'weights-improvement-14-0.4270.keras', 'weights-improvement-36-1.0690.keras', 'weights-improvement-18-1.1946.keras', 'weights-improvement-29-0.4973.keras', 'weights-improvement-28-0.6292.keras', 'weights-improvement-100-1.4337.keras', 'weights-improvement-83-1.6409.keras', 'weights-improvement-12-0.6525.keras', 'weights-improvement-36-0.4179.keras', 'weights-improvement-31-1.0991.keras', 'weights-improvement-34-2.8968.keras', 'weights-improvement-94-0.4405.keras', 'weights-improvement-83-0.5554.keras', 'weights-improvement-99-0.5383.keras', 'weights-improvement-40-0.4119.keras', 'weights-improvement-84-0.8643.keras', 'weights-improvement-66-0.9351.keras', 'weights-improvement-09-0.3151.keras', 'weights-improvement-46-2.4080.keras', 'weights-improvement-67-0.9296.keras']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Generate text from the model\n",
        "def generate_text(seed_text, next_words, model, tokenizer, max_sequence_len, words_per_line=20):\n",
        "    generated_text = \"\"\n",
        "    word_count = 0\n",
        "\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len, padding='pre')\n",
        "        prediction = model.predict(token_list, verbose=0)\n",
        "        prediction = np.asarray(prediction).astype('float64')\n",
        "        prediction = np.log(prediction + 1e-7) / 1.0  # Experiment with temperature\n",
        "        exp_preds = np.exp(prediction)\n",
        "        prediction = exp_preds / np.sum(exp_preds)\n",
        "        index = np.argmax(np.random.multinomial(1, prediction[0], 1))\n",
        "        output_word = \"\"\n",
        "        for word, idx in tokenizer.word_index.items():\n",
        "            if idx == index:\n",
        "                output_word = word\n",
        "                break\n",
        "\n",
        "        seed_text += \" \" + output_word\n",
        "        seed_text = seed_text.split(' ')[-max_sequence_len:]\n",
        "        seed_text = ' '.join(seed_text)\n",
        "\n",
        "        # Add the generated word to the output and manage line breaks\n",
        "        generated_text += output_word + \" \"\n",
        "        word_count += 1\n",
        "        if word_count % words_per_line == 0:\n",
        "            generated_text += \"\\n\"\n",
        "\n",
        "    return generated_text\n",
        "\n",
        "# Pick a random seed\n",
        "start_index = random.randint(0, len(sequences) - seq_length - 1)\n",
        "seed_text = ' '.join([list(tokenizer.word_index.keys())[word - 1] for word in sequences[start_index: start_index + seq_length]])\n",
        "print(\"Seed:\")\n",
        "print(seed_text)\n",
        "\n",
        "# Generate words with paragraph formatting\n",
        "print(\"\\nGenerated text:\")\n",
        "print(generate_text(seed_text, 25, model, tokenizer, seq_length))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXKMhtUaiJ2h",
        "outputId": "1eb8b527-6b8c-43e1-a3a3-c6378623d068"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed:\n",
            "puppy began a series of short charges at the stick running a very little way forwards each time and a long way back and barking hoarsely all the while till at last it sat down a good way off panting with its tongue hanging out of its mouth and its\n",
            "\n",
            "Generated text:\n",
            "great eyes half shut this seemed to alice a good opportunity for making her escape so she set off at \n",
            "once and ran till she \n"
          ]
        }
      ]
    }
  ]
}